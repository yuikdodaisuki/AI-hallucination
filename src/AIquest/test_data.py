import sys
import os
import re
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(current_dir))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from src.AIquest.utils.data_reader import DataReader

def debug_text_extraction():
    """è°ƒè¯•æ–‡æœ¬æå–è¿‡ç¨‹"""
    data_reader = DataReader()
    
    # ä½¿ç”¨ç»å¯¹è·¯å¾„
    consolidated_file = os.path.join(project_root, "src", "data", "consolidated", "ESIå‰1%å­¦ç§‘æ•°é‡_data.json")
    
    print(f"ğŸ” æµ‹è¯•æ–‡æœ¬æå–åŠŸèƒ½")
    print(f"ğŸ“‚ é¡¹ç›®æ ¹ç›®å½•: {project_root}")
    print(f"ğŸ“ æ•°æ®æ–‡ä»¶è·¯å¾„: {consolidated_file}")
    print(f"âœ… æ–‡ä»¶æ˜¯å¦å­˜åœ¨: {os.path.exists(consolidated_file)}")
    
    if os.path.exists(consolidated_file):
        # è°ƒç”¨æ–‡æœ¬æå–æ–¹æ³•
        extracted_text = data_reader.extract_text_content(consolidated_file)
        
        print(f"\nğŸ“ æå–ç»“æœ:")
        print(f"æ–‡æœ¬é•¿åº¦: {len(extracted_text)} å­—ç¬¦")
        
        # ğŸ”¥ è¾“å‡ºå®Œæ•´çš„æå–æ–‡æœ¬ï¼ˆåˆ†æ®µæ˜¾ç¤ºé¿å…è¿‡é•¿ï¼‰ğŸ”¥
        print(f"\nğŸ“„ å®Œæ•´æå–æ–‡æœ¬:")
        print("=" * 80)
        
        # æŒ‰è¡Œæ˜¾ç¤ºï¼Œä¾¿äºæŸ¥çœ‹ç»“æ„
        lines = extracted_text.split('\n')
        print(f"æ€»è¡Œæ•°: {len(lines)}")
        
        # æ˜¾ç¤ºå‰50è¡Œ
        print(f"\nğŸ“‹ å‰50è¡Œ:")
        print("-" * 60)
        for i, line in enumerate(lines[:50]):
            print(f"{i+1:3d}: {line}")
        
        # ğŸ”¥ æŸ¥æ‰¾å¹¶æ˜¾ç¤ºä¸­å±±å¤§å­¦ç›¸å…³çš„å®Œæ•´æ•°æ®å— ğŸ”¥
        print(f"\nğŸ¯ ä¸­å±±å¤§å­¦ç›¸å…³æ•°æ®:")
        print("-" * 60)
        zhongshan_indices = []
        for i, line in enumerate(lines):
            if 'ä¸­å±±å¤§å­¦' in line:
                zhongshan_indices.append(i)
        
        if zhongshan_indices:
            for idx in zhongshan_indices:
                print(f"æ‰¾åˆ°ä¸­å±±å¤§å­¦åœ¨ç¬¬{idx+1}è¡Œ: {lines[idx]}")
                # æ˜¾ç¤ºå‰å10è¡Œä½œä¸ºä¸Šä¸‹æ–‡
                start = max(0, idx-5)
                end = min(len(lines), idx+6)
                print(f"ä¸Šä¸‹æ–‡ (ç¬¬{start+1}-{end}è¡Œ):")
                for j in range(start, end):
                    marker = ">>> " if j == idx else "    "
                    print(f"{marker}{j+1:3d}: {lines[j]}")
                print()
        
        # ğŸ”¥ æœç´¢å…³é”®å­—æ®µ ğŸ”¥
        print(f"\nğŸ”‘ å…³é”®å­—æ®µæ£€æŸ¥:")
        print("-" * 60)
        key_fields = ['å‰1%æ•°', 'å‰1â€°æ•°', 'å­¦æ ¡å', 'å…¨çƒæ’å', 'ESI']
        for field in key_fields:
            count = extracted_text.count(field)
            print(f"'{field}': å‡ºç° {count} æ¬¡")
            if count > 0:
                # æ˜¾ç¤ºå‰3ä¸ªåŒ¹é…çš„è¡Œ
                matching_lines = [line for line in lines if field in line]
                print(f"  ç¤ºä¾‹: {matching_lines[:3]}")
        
        # ğŸ”¥ æ£€æŸ¥æ•°æ®è´¨é‡ ğŸ”¥
        print(f"\nğŸ“Š æ•°æ®è´¨é‡åˆ†æ:")
        print("-" * 60)
        if 'å­¦æ ¡å' in extracted_text and 'å‰1%æ•°' in extracted_text:
            print(f"âœ… æ•°æ®åŒ…å«æ­£ç¡®çš„å­—æ®µç»“æ„")
        else:
            print(f"âŒ æ•°æ®å­—æ®µç»“æ„å¼‚å¸¸")
        
        if 'ä¸­å±±å¤§å­¦' in extracted_text:
            print(f"âœ… æå–çš„æ–‡æœ¬åŒ…å«'ä¸­å±±å¤§å­¦'")
        else:
            print(f"âŒ æå–çš„æ–‡æœ¬ä¸åŒ…å«'ä¸­å±±å¤§å­¦'")
        
        # ğŸ”¥ æ£€æŸ¥æ˜¯å¦åŒ…å«æ•°å­—æ•°æ® ğŸ”¥
        number_lines = [line for line in lines if any(char.isdigit() for char in line)]
        print(f"åŒ…å«æ•°å­—çš„è¡Œæ•°: {len(number_lines)}")
        if len(number_lines) > 0:
            print(f"æ•°å­—è¡Œç¤ºä¾‹:")
            for line in number_lines[:5]:
                print(f"  {line}")
        
        # ğŸ”¥ ä¿å­˜æå–çš„æ–‡æœ¬åˆ°æ–‡ä»¶ï¼Œä¾¿äºè¯¦ç»†æŸ¥çœ‹ ğŸ”¥
        output_file = os.path.join(project_root, "debug_extracted_text.txt")
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(f"ESIæ•°æ®æå–ç»“æœ\n")
            f.write(f"=" * 80 + "\n")
            f.write(f"æ–‡ä»¶: {consolidated_file}\n")
            f.write(f"æå–æ—¶é—´: {os.path.getctime(consolidated_file)}\n")
            f.write(f"æ–‡æœ¬é•¿åº¦: {len(extracted_text)} å­—ç¬¦\n")
            f.write(f"æ€»è¡Œæ•°: {len(lines)}\n")
            f.write(f"\nå®Œæ•´æå–æ–‡æœ¬:\n")
            f.write("-" * 80 + "\n")
            f.write(extracted_text)
        
        print(f"\nğŸ’¾ å®Œæ•´æå–æ–‡æœ¬å·²ä¿å­˜åˆ°: {output_file}")
        
    else:
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {consolidated_file}")
        
        # åˆ—å‡ºå®é™…å­˜åœ¨çš„æ–‡ä»¶
        consolidated_dir = os.path.join(project_root, "src", "data", "consolidated")
        if os.path.exists(consolidated_dir):
            print(f"ğŸ“‚ consolidatedç›®å½•å†…å®¹:")
            files = os.listdir(consolidated_dir)
            for file in files:
                file_path = os.path.join(consolidated_dir, file)
                file_size = os.path.getsize(file_path)
                print(f"  - {file} ({file_size} bytes)")

if __name__ == "__main__":
    debug_text_extraction()