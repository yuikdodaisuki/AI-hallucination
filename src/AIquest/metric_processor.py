"""æŒ‡æ ‡æ•°æ®å¤„ç†å™¨"""
import csv
import os
from src.AIquest.utils.llm_client import LLMClient
from src.AIquest.utils.data_reader import DataReader
from src.AIquest.utils.question_processor import QuestionProcessor
from src.AIquest.utils.file_utils import FileUtils
from src.AIquest.config import (
    METRIC_DATA_MAPPING, OUTPUT_CONFIG, METRIC_CATEGORIES, DATA_SOURCES,
    is_school_extraction_enabled, get_consolidated_dir_path
)


class MetricDataProcessor:
    """æ ¹æ®æŒ‡æ ‡ç±»å‹å¤„ç†æ•°æ®å’Œé—®é¢˜çš„ä¸»ç±»"""
    
    def __init__(self, config_path=None):
        self.llm_client = LLMClient(config_path)
        self.data_reader = DataReader()
        self.question_processor = QuestionProcessor(self.llm_client, self.data_reader)
        self.file_utils = FileUtils()
        # ğŸ”¥ æ–°å¢ï¼šæ˜¾ç¤ºå½“å‰å¤„ç†æ¨¡å¼ ğŸ”¥
        mode = "æ™ºèƒ½æˆªå–æ¨¡å¼" if is_school_extraction_enabled() else "ä¼ ç»Ÿæ¨¡å¼"
        print(f"ğŸ“‹ MetricDataProcessor åˆå§‹åŒ–å®Œæˆï¼Œå½“å‰é™„ä»¶å¤„ç†æ¨¡å¼: {mode}")
    
    def process_metric_questions(self, metric_name, questions_csv_path, output_csv_path):
        """å¤„ç†ç‰¹å®šæŒ‡æ ‡çš„é—®é¢˜ - æ”¯æŒåŠ¨æ€æ•°æ®æ–‡ä»¶é€‰æ‹©"""
        print(f"\nå¼€å§‹å¤„ç†æŒ‡æ ‡: {metric_name}")
        
        # æ˜¾ç¤ºå½“å‰å¤„ç†æ¨¡å¼
        mode = "æ™ºèƒ½æˆªå–æ¨¡å¼" if is_school_extraction_enabled() else "ä¼ ç»Ÿæ¨¡å¼"
        print(f"ğŸ“‚ å½“å‰é™„ä»¶å¤„ç†æ¨¡å¼: {mode}")
        
        # éªŒè¯æŒ‡æ ‡æ˜¯å¦åœ¨æ”¯æŒçš„åˆ—è¡¨ä¸­
        if not self._validate_metric(metric_name):
            return False
        
        # ğŸ”¥ ä¿®æ”¹ï¼šä½¿ç”¨æ–°çš„æ•°æ®æ–‡ä»¶è·å–é€»è¾‘ ğŸ”¥
        # 1. é¦–å…ˆæ£€æŸ¥æ˜¯å¦æœ‰å¯¹åº”æ¨¡å¼çš„ç°æˆæ–‡ä»¶
        consolidated_data_path = self._get_or_create_metric_data_file(metric_name)
        if not consolidated_data_path:
            print(f"é”™è¯¯: æœªèƒ½ä¸ºæŒ‡æ ‡ '{metric_name}' è·å–æˆ–åˆ›å»ºæ•°æ®æ–‡ä»¶")
            return False
        
        # 2. æ˜¾ç¤ºä½¿ç”¨çš„æ•°æ®æ–‡ä»¶ä¿¡æ¯
        self._show_data_file_info(consolidated_data_path)
        
        # 3. ç­›é€‰å‡ºè¯¥æŒ‡æ ‡çš„é—®é¢˜
        metric_questions = self.question_processor.filter_questions_by_metric(questions_csv_path, metric_name)
        if not metric_questions:
            print(f"è­¦å‘Š: æœªæ‰¾åˆ°æŒ‡æ ‡ '{metric_name}' çš„ç›¸å…³é—®é¢˜")
            return False
        
        # 4. å¤„ç†é—®é¢˜å¹¶è·å–ç­”æ¡ˆ
        return self.question_processor.process_metric_questions(
            metric_questions, consolidated_data_path, output_csv_path, metric_name
        )
    
    def _get_or_create_metric_data_file(self, metric_name):
        """ğŸ”¥ æ–°å¢ï¼šè·å–æˆ–åˆ›å»ºæŒ‡æ ‡å¯¹åº”çš„æ•°æ®æ–‡ä»¶ ğŸ”¥"""
        # é¦–å…ˆå°è¯•æŸ¥æ‰¾ç°æœ‰æ–‡ä»¶
        existing_file = self.data_reader.find_existing_consolidated_file(metric_name)
        
        if existing_file:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸å½“å‰æ¨¡å¼åŒ¹é…
            file_info = self.data_reader.get_consolidated_file_info(metric_name)
            if file_info:
                current_mode = "intelligent" if is_school_extraction_enabled() else "traditional"
                file_mode = file_info.get('processing_mode', 'unknown')
                
                if file_mode == current_mode:
                    print(f"  âœ… æ‰¾åˆ°åŒ¹é…å½“å‰æ¨¡å¼çš„æ•°æ®æ–‡ä»¶")
                    return existing_file
                else:
                    print(f"  âš ï¸  ç°æœ‰æ–‡ä»¶æ¨¡å¼ä¸åŒ¹é…:")
                    print(f"      æ–‡ä»¶æ¨¡å¼: {file_mode}")
                    print(f"      å½“å‰æ¨¡å¼: {current_mode}")
                    print(f"  ğŸ”„ å°†é‡æ–°ç”ŸæˆåŒ¹é…å½“å‰æ¨¡å¼çš„æ•°æ®æ–‡ä»¶...")
        else:
            print(f"  ğŸ“ æœªæ‰¾åˆ°ç°æœ‰æ•°æ®æ–‡ä»¶ï¼Œå°†é‡æ–°ç”Ÿæˆ...")
        
        # é‡æ–°ç”Ÿæˆæ•°æ®æ–‡ä»¶
        data_sources = METRIC_DATA_MAPPING.get(metric_name, [])
        if not data_sources:
            print(f"é”™è¯¯: æœªæ‰¾åˆ°æŒ‡æ ‡ '{metric_name}' å¯¹åº”çš„æ•°æ®æºé…ç½®")
            return None
        
        print(f"  ğŸ”„ é‡æ–°æ•´åˆæ•°æ®æº: {data_sources}")
        return self.data_reader.consolidate_data_for_metric(metric_name, data_sources)
    
    def _show_data_file_info(self, data_file_path):
        """ğŸ”¥ æ–°å¢ï¼šæ˜¾ç¤ºæ•°æ®æ–‡ä»¶ä¿¡æ¯ ğŸ”¥"""
        if not data_file_path or not os.path.exists(data_file_path):
            print(f"  âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_file_path}")
            return
        
        try:
            import json
            with open(data_file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            file_name = os.path.basename(data_file_path)
            processing_mode = data.get('processing_mode', 'unknown')
            total_items = data.get('total_items', 0)
            status = data.get('status', 'unknown')
            generated_at = data.get('generated_at', 'unknown')
            
            print(f"  ğŸ“„ ä½¿ç”¨æ•°æ®æ–‡ä»¶: {file_name}")
            print(f"      å¤„ç†æ¨¡å¼: {processing_mode}")
            print(f"      æ•°æ®æ¡æ•°: {total_items}")
            print(f"      æ–‡ä»¶çŠ¶æ€: {status}")
            print(f"      ç”Ÿæˆæ—¶é—´: {generated_at}")
            
        except Exception as e:
            print(f"  âš ï¸  æ— æ³•è¯»å–æ•°æ®æ–‡ä»¶ä¿¡æ¯: {e}")
    
    def _validate_metric(self, metric_name):
        """éªŒè¯æŒ‡æ ‡æ˜¯å¦åœ¨æ–°çš„æ”¯æŒåˆ—è¡¨ä¸­"""
        all_supported_metrics = (
            METRIC_CATEGORIES['subject_metrics'] + 
            METRIC_CATEGORIES['major_metrics'] + 
            METRIC_CATEGORIES['teaching_metrics']
        )

        if metric_name not in all_supported_metrics:
            print(f"âŒ ä¸æ”¯æŒçš„æŒ‡æ ‡: {metric_name}")
            print("âœ… æ”¯æŒçš„æŒ‡æ ‡åˆ—è¡¨:")
            print("  ğŸ“š å­¦ç§‘æŒ‡æ ‡:")
            for metric in METRIC_CATEGORIES['subject_metrics']:
                print(f"    - {metric}")
            print("  ğŸ“ ä¸“ä¸šæŒ‡æ ‡:")
            for metric in METRIC_CATEGORIES['major_metrics']:
                print(f"    - {metric}")
            for metric in METRIC_CATEGORIES['teaching_metrics']:
                print(f"    - {metric}")
            return False
        
        return True
    
    def process_all_metrics(self, questions_csv_path, output_base_path):
        """å¤„ç†æ‰€æœ‰æŒ‡æ ‡çš„é—®é¢˜ - æ”¯æŒåŠ¨æ€æ•°æ®æ–‡ä»¶"""
        print(f"\nğŸš€ å¼€å§‹å¤„ç†æ‰€æœ‰æŒ‡æ ‡")
        mode = "æ™ºèƒ½æˆªå–æ¨¡å¼" if is_school_extraction_enabled() else "ä¼ ç»Ÿæ¨¡å¼"
        print(f"ğŸ“‚ å½“å‰é™„ä»¶å¤„ç†æ¨¡å¼: {mode}")
        
        # è·å–æ‰€æœ‰å”¯ä¸€çš„æŒ‡æ ‡
        all_metrics = set()
        try:
            with open(questions_csv_path, mode='r', encoding=OUTPUT_CONFIG['file_encoding']) as csvfile:
                reader = csv.DictReader(csvfile)
                for row in reader:
                    metric = row.get('æŒ‡æ ‡åç§°')
                    if metric and metric != 'å¾…å¡«å……':
                        all_metrics.add(metric)
        except Exception as e:
            print(f"è¯»å–é—®é¢˜æ–‡ä»¶å¤±è´¥: {e}")
            return False
        
        print(f"å‘ç° {len(all_metrics)} ä¸ªä¸åŒçš„æŒ‡æ ‡éœ€è¦å¤„ç†")
        
        # éªŒè¯æ‰€æœ‰æŒ‡æ ‡éƒ½è¢«æ”¯æŒ
        unsupported_metrics = []
        for metric in all_metrics:
            if not self._validate_metric_silent(metric):
                unsupported_metrics.append(metric)
        
        if unsupported_metrics:
            print(f"âš ï¸  å‘ç° {len(unsupported_metrics)} ä¸ªä¸æ”¯æŒçš„æŒ‡æ ‡:")
            for metric in unsupported_metrics:
                print(f"    - {metric}")
            print("è¯·æ£€æŸ¥é…ç½®æ–‡ä»¶æˆ–æ›´æ–°æŒ‡æ ‡æ˜ å°„")
        
        # åªå¤„ç†æ”¯æŒçš„æŒ‡æ ‡
        supported_metrics = [m for m in all_metrics if self._validate_metric_silent(m)]
        print(f"âœ… å°†å¤„ç† {len(supported_metrics)} ä¸ªæ”¯æŒçš„æŒ‡æ ‡")
        
        # ğŸ”¥ æ–°å¢ï¼šä¸ºæ‰€æœ‰æŒ‡æ ‡é¢„å…ˆå‡†å¤‡æ•°æ®æ–‡ä»¶ ğŸ”¥
        print(f"\nğŸ“Š é¢„å…ˆå‡†å¤‡æ‰€æœ‰æŒ‡æ ‡çš„æ•°æ®æ–‡ä»¶...")
        prepared_files = {}
        for i, metric in enumerate(supported_metrics, 1):
            print(f"\n[{i}/{len(supported_metrics)}] å‡†å¤‡æŒ‡æ ‡: {metric}")
            data_file = self._get_or_create_metric_data_file(metric)
            if data_file:
                prepared_files[metric] = data_file
                print(f"  âœ… æ•°æ®æ–‡ä»¶å‡†å¤‡å®Œæˆ")
            else:
                print(f"  âŒ æ•°æ®æ–‡ä»¶å‡†å¤‡å¤±è´¥")
        
        print(f"\nğŸ“ˆ æ•°æ®æ–‡ä»¶å‡†å¤‡æ±‡æ€»:")
        print(f"  æˆåŠŸ: {len(prepared_files)}/{len(supported_metrics)} ä¸ªæŒ‡æ ‡")
        
        # ä¸ºæ¯ä¸ªæœ‰æ•°æ®æ–‡ä»¶çš„æŒ‡æ ‡å¤„ç†é—®é¢˜
        all_results = []
        for i, metric in enumerate(supported_metrics, 1):
            if metric in prepared_files:
                print(f"\n[{i}/{len(supported_metrics)}] ğŸ”„ å¤„ç†æŒ‡æ ‡: {metric}")
                output_path = f"{output_base_path}_{metric}_answers.csv"
                success = self.process_metric_questions(metric, questions_csv_path, output_path)
                if success:
                    all_results.append(output_path)
                    print(f"  âœ… æŒ‡æ ‡ '{metric}' å¤„ç†å®Œæˆ")
                else:
                    print(f"  âŒ æŒ‡æ ‡ '{metric}' å¤„ç†å¤±è´¥")
            else:
                print(f"\n[{i}/{len(supported_metrics)}] â­ï¸  è·³è¿‡æŒ‡æ ‡ '{metric}' (æ— å¯ç”¨æ•°æ®)")
        
        # åˆå¹¶æ‰€æœ‰ç»“æœ
        if all_results:
            final_output_path = f"{output_base_path}_all_answers.csv"
            print(f"\nğŸ“‹ åˆå¹¶æ‰€æœ‰ç»“æœåˆ°: {final_output_path}")
            self.file_utils.merge_csv_files(all_results, final_output_path)
            print(f"âœ… æ‰€æœ‰æŒ‡æ ‡å¤„ç†å®Œæˆï¼Œå…±ç”Ÿæˆ {len(all_results)} ä¸ªç»“æœæ–‡ä»¶")
        else:
            print(f"\nâŒ æœªç”Ÿæˆä»»ä½•ç»“æœæ–‡ä»¶")
        
        return len(all_results) > 0
    
    # ğŸ”¥ æ–°å¢ï¼šæ•°æ®æ–‡ä»¶ç®¡ç†æ–¹æ³• ğŸ”¥
    def show_data_files_status(self):
        """æ˜¾ç¤ºæ‰€æœ‰æŒ‡æ ‡çš„æ•°æ®æ–‡ä»¶çŠ¶æ€"""
        print("ğŸ“‚ æ•°æ®æ–‡ä»¶çŠ¶æ€æ±‡æ€»")
        print("=" * 60)
        
        current_mode = "intelligent" if is_school_extraction_enabled() else "traditional"
        mode_name = "æ™ºèƒ½æˆªå–æ¨¡å¼" if current_mode == "intelligent" else "ä¼ ç»Ÿæ¨¡å¼"
        print(f"ğŸ”§ å½“å‰æ¨¡å¼: {mode_name}")
        print()
        
        all_files = self.data_reader.list_all_consolidated_files()
        
        if not all_files:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•æ•°æ®æ–‡ä»¶")
            return
        
        # æŒ‰æŒ‡æ ‡æ˜¾ç¤º
        for metric_name, modes in all_files.items():
            print(f"ğŸ“Š {metric_name}:")
            
            # å½“å‰æ¨¡å¼çš„æ–‡ä»¶
            if current_mode in modes:
                info = modes[current_mode]
                if 'error' in info:
                    print(f"  âœ… å½“å‰æ¨¡å¼: âŒ {info['error']}")
                else:
                    print(f"  âœ… å½“å‰æ¨¡å¼: {info['total_items']} æ¡è®°å½• (ä¿®æ”¹: {info['modified_time']})")
            else:
                print(f"  âšª å½“å‰æ¨¡å¼: æ— æ•°æ®æ–‡ä»¶")
            
            # å…¶ä»–æ¨¡å¼çš„æ–‡ä»¶
            other_mode = "traditional" if current_mode == "intelligent" else "intelligent"
            if other_mode in modes:
                info = modes[other_mode]
                other_mode_name = "ä¼ ç»Ÿæ¨¡å¼" if other_mode == "traditional" else "æ™ºèƒ½æ¨¡å¼"
                if 'error' in info:
                    print(f"  ğŸ“‹ {other_mode_name}: âŒ {info['error']}")
                else:
                    print(f"  ğŸ“‹ {other_mode_name}: {info['total_items']} æ¡è®°å½• (ä¿®æ”¹: {info['modified_time']})")
            
            print()
    
    def regenerate_all_data_files(self):
        """ğŸ”¥ æ–°å¢ï¼šé‡æ–°ç”Ÿæˆæ‰€æœ‰æ•°æ®æ–‡ä»¶ ğŸ”¥"""
        print("ğŸ”„ é‡æ–°ç”Ÿæˆæ‰€æœ‰æŒ‡æ ‡çš„æ•°æ®æ–‡ä»¶")
        mode = "æ™ºèƒ½æˆªå–æ¨¡å¼" if is_school_extraction_enabled() else "ä¼ ç»Ÿæ¨¡å¼"
        print(f"ğŸ“‚ å½“å‰æ¨¡å¼: {mode}")
        print()
        
        success_count = 0
        total_count = len(METRIC_DATA_MAPPING)
        
        for i, metric_name in enumerate(METRIC_DATA_MAPPING.keys(), 1):
            print(f"[{i}/{total_count}] ğŸ”„ é‡æ–°ç”Ÿæˆ: {metric_name}")
            
            data_sources = METRIC_DATA_MAPPING[metric_name]
            consolidated_file = self.data_reader.consolidate_data_for_metric(metric_name, data_sources)
            
            if consolidated_file:
                print(f"  âœ… ç”ŸæˆæˆåŠŸ")
                success_count += 1
            else:
                print(f"  âŒ ç”Ÿæˆå¤±è´¥")
            print()
        
        print(f"ğŸ“ˆ é‡æ–°ç”Ÿæˆå®Œæˆ: {success_count}/{total_count} ä¸ªæŒ‡æ ‡")
        return success_count == total_count
    
    def _validate_metric_silent(self, metric_name):
        """é™é»˜éªŒè¯æŒ‡æ ‡ï¼ˆä¸æ‰“å°é”™è¯¯ä¿¡æ¯ï¼‰"""
        all_supported_metrics = (
            METRIC_CATEGORIES['subject_metrics'] + 
            METRIC_CATEGORIES['major_metrics'] +
            METRIC_CATEGORIES['teaching_metrics']
        )
        return metric_name in all_supported_metrics
    
    def get_available_metrics(self):
        """è·å–æ‰€æœ‰å¯ç”¨çš„æŒ‡æ ‡ï¼ˆæŒ‰ç±»åˆ«åˆ†ç»„ï¼‰"""
        return {
            'subject_metrics': METRIC_CATEGORIES['subject_metrics'],
            'major_metrics': METRIC_CATEGORIES['major_metrics'],
            'teaching_metrics': METRIC_CATEGORIES['teaching_metrics'],
            'all_metrics': METRIC_CATEGORIES['subject_metrics'] + METRIC_CATEGORIES['major_metrics'] + METRIC_CATEGORIES['teaching_metrics']
        }
    
    def validate_data_sources(self):
        """éªŒè¯æ•°æ®æºæ˜¯å¦å­˜åœ¨"""
        print("ğŸ” éªŒè¯æ•°æ®æº...")
        current_dir = os.path.dirname(os.path.abspath(__file__))
        
        for metric, sources in METRIC_DATA_MAPPING.items():
            print(f"  ğŸ“Š æŒ‡æ ‡: {metric}")
            for source in sources:
                source_path = os.path.join(current_dir, '../../data', 
                                         DATA_SOURCES.get(source, source).replace('../../data/', ''))
                exists = os.path.exists(source_path)
                status = 'âœ…' if exists else 'âŒ'
                print(f"    {status} æ•°æ®æº {source}: {source_path}")
    
    def get_metric_statistics(self, questions_csv_path):
        """è·å–æŒ‡æ ‡ç»Ÿè®¡ä¿¡æ¯"""
        metric_stats = {}
        school_count = 0
        
        try:
            with open(questions_csv_path, mode='r', encoding=OUTPUT_CONFIG['file_encoding']) as csvfile:
                reader = csv.DictReader(csvfile)
                schools = set()
                
                for row in reader:
                    metric = row.get('æŒ‡æ ‡åç§°')
                    school = row.get('å­¦æ ¡åç§°')
                    
                    if metric and metric != 'å¾…å¡«å……':
                        if metric not in metric_stats:
                            metric_stats[metric] = 0
                        metric_stats[metric] += 1
                    
                    if school:
                        schools.add(school)
                
                school_count = len(schools)
        
        except Exception as e:
            print(f"ç»Ÿè®¡æŒ‡æ ‡ä¿¡æ¯å¤±è´¥: {e}")
            return None
        
        return {
            'total_schools': school_count,
            'total_questions': sum(metric_stats.values()),
            'metrics_distribution': metric_stats,
            'supported_metrics': {k: v for k, v in metric_stats.items() if self._validate_metric_silent(k)},
            'unsupported_metrics': {k: v for k, v in metric_stats.items() if not self._validate_metric_silent(k)}
        }