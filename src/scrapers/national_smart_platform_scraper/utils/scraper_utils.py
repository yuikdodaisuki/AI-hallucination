import asyncio
import os
import json
import re
import tempfile
import time
from typing import List, Optional, Tuple
from urllib.parse import quote
from pydantic import BaseModel, Field

from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode, LLMConfig, CrawlResult
from crawl4ai.extraction_strategy import LLMExtractionStrategy
from crawl4ai import *

from models.course import Course
from config import *


def get_browser_config() -> BrowserConfig:
    """
    è·å–æµè§ˆå™¨é…ç½®
    """
    print("ğŸ”§ é…ç½®æµè§ˆå™¨å‚æ•°...")
    config = BrowserConfig(
        browser_type="chromium",
        headless=False,  # è®¾ä¸ºFalseä¾¿äºè°ƒè¯•è§‚å¯Ÿ
        verbose=True,
    )
    print("âœ… æµè§ˆå™¨é…ç½®å®Œæˆ")
    return config


def build_school_search_url(school_name: str) -> str:
    """
    æ„å»ºå­¦æ ¡æœç´¢URL
    """
    encoded_school = quote(school_name)
    return SEARCH_URL_TEMPLATE.format(school_name=encoded_school)


def create_auto_chunking_llm_strategy(school_name: str) -> LLMExtractionStrategy:
    """
    ğŸ”¥ åˆ›å»ºå®Œå…¨ä½¿ç”¨Crawl4aiè‡ªåŠ¨åˆ†å—çš„LLMç­–ç•¥
    """
    print("ğŸ¤– åˆ›å»ºè‡ªåŠ¨åˆ†å—LLMæå–ç­–ç•¥...")
    
    extraction_instruction = f"""ä½ æ˜¯ä¸“ä¸šçš„è¯¾ç¨‹ä¿¡æ¯æå–ä¸“å®¶ã€‚è¯·ä»ä»¥ä¸‹"{school_name}"çš„ç½‘é¡µå†…å®¹ä¸­æå–æ‰€æœ‰è¯¾ç¨‹ä¿¡æ¯ã€‚

**ä¸¥æ ¼æå–è¦æ±‚ï¼š**
1. ä»”ç»†åˆ†ææ•´ä¸ªå†…å®¹ï¼Œæå–æ¯ä¸€é—¨å…·ä½“è¯¾ç¨‹åŠå…¶å¯¹åº”æ•™å¸ˆ
2. è¯¾ç¨‹åç§°ï¼šå…·ä½“çš„å­¦ç§‘åç§°ï¼ˆå¦‚"é«˜ç­‰æ•°å­¦"ã€"å¤§å­¦è‹±è¯­"ã€"ç¨‹åºè®¾è®¡"ç­‰ï¼‰
3. æ•™å¸ˆå§“åï¼šçœŸå®çš„äººåï¼ˆ2-4ä¸ªä¸­æ–‡å­—ç¬¦æˆ–å®Œæ•´è‹±æ–‡å§“åï¼‰
4. ç¡®ä¿ä¸é—æ¼ä»»ä½•è¯¾ç¨‹ä¿¡æ¯ï¼Œä½†é¿å…é‡å¤æå–
5. å¿½ç•¥å¯¼èˆªèœå•ã€å¹¿å‘Šã€é¡µè„šç­‰æ— å…³å†…å®¹

**è¾“å‡ºæ ¼å¼ï¼ˆä¸¥æ ¼JSONæ•°ç»„ï¼‰ï¼š**
[
  {{"school": "{school_name}", "course": "è¯¾ç¨‹åç§°", "teacher": "æ•™å¸ˆå§“å"}},
  {{"school": "{school_name}", "course": "è¯¾ç¨‹åç§°", "teacher": "æ•™å¸ˆå§“å"}}
]

**é‡è¦è¯´æ˜ï¼š**
- è¿™å¯èƒ½æ˜¯å†…å®¹ç‰‡æ®µï¼Œè¯·æå–ç‰‡æ®µä¸­çš„æ‰€æœ‰å®Œæ•´è¯¾ç¨‹ä¿¡æ¯
- å¦‚æœç¡®å®æ²¡æœ‰æ˜ç¡®çš„è¯¾ç¨‹-æ•™å¸ˆå¯¹åº”å…³ç³»ï¼Œè¿”å›ç©ºæ•°ç»„ []
- ä¸è¦çŒœæµ‹æˆ–æ¨æ–­ä¿¡æ¯ï¼Œåªæå–æ˜ç¡®æ˜¾ç¤ºçš„å†…å®¹
- ç¡®ä¿æ¯ä¸ªcourseå’Œteacherå­—æ®µéƒ½æœ‰å®é™…å†…å®¹ä¸”éç©º

è¯·å¼€å§‹è¯¦ç»†æå–ï¼š"""
    
    llm_strategy = LLMExtractionStrategy(
        llm_config=LLMConfig(
            provider=LLM_MODEL,
            api_token=os.getenv(API_KEY_ENV, os.getenv("DEEPSEEK_API_KEY")),
            base_url=LLM_BASE_URL,
        ),
        schema=f'[{{"school": "{school_name}", "course": "str", "teacher": "str"}}]',
        extraction_type="schema",
        instruction=extraction_instruction,
        
        # ğŸ”¥ æ ¸å¿ƒï¼šå¯ç”¨Crawl4aiè‡ªåŠ¨åˆ†å—
        apply_chunking=True,           # å¯ç”¨è‡ªåŠ¨åˆ†å—
        chunk_token_threshold=6000,    # 6000 tokens çš„åˆ†å—å¤§å°
        overlap_rate=0.15,             # 15% é‡å ç‡ï¼Œé˜²æ­¢è¯¾ç¨‹ä¿¡æ¯ä¸¢å¤±
        
        input_format="markdown",
        extra_args={
            "temperature": 0.0,        # ç¡®ä¿è¾“å‡ºç¨³å®š
            "max_tokens": 8000,        # è¶³å¤Ÿçš„è¾“å‡ºç©ºé—´
            "top_p": 0.1,              # å‡å°‘éšæœºæ€§
        }
    )
    
    print("âœ… è‡ªåŠ¨åˆ†å—LLMç­–ç•¥åˆ›å»ºå®Œæˆ")
    return llm_strategy


def validate_course_data(course_data: dict) -> bool:
    """
    ğŸ” éªŒè¯æå–çš„è¯¾ç¨‹æ•°æ®è´¨é‡
    """
    course_name = course_data.get('course', '').strip()
    teacher_name = course_data.get('teacher', '').strip()
    
    # åŸºæœ¬é•¿åº¦æ£€æŸ¥
    if len(course_name) < 2 or len(teacher_name) < 2:
        return False
    
    # è¿‡æ»¤æ˜æ˜¾é”™è¯¯çš„è¯¾ç¨‹åç§°
    invalid_course_patterns = [
        r'^(è¯¦æƒ…|æ›´å¤š|æŸ¥çœ‹|ç‚¹å‡»|é“¾æ¥|æŒ‰é’®|ç™»å½•|æ³¨å†Œ|é¦–é¡µ|å¯¼èˆª|èœå•).*',
        r'.*\.(com|cn|org|net).*',
        r'^\d+$',  # çº¯æ•°å­—
        r'^(null|undefined|none|æš‚æ— |å¾…å®š|tbd).*'
    ]
    
    for pattern in invalid_course_patterns:
        if re.match(pattern, course_name, re.IGNORECASE):
            return False
    
    # è¿‡æ»¤æ˜æ˜¾é”™è¯¯çš„æ•™å¸ˆåç§°
    invalid_teacher_patterns = [
        r'^(è¯¦æƒ…|æ›´å¤š|æŸ¥çœ‹|ç‚¹å‡»|é“¾æ¥|æŒ‰é’®|å­¦æ ¡|å­¦é™¢|ç³»|éƒ¨é—¨).*',
        r'.*\.(com|cn|org|net).*',
        r'^\d+$',  # çº¯æ•°å­—
        r'^(null|undefined|none|æš‚æ— |å¾…å®š|tbd).*'
    ]
    
    for pattern in invalid_teacher_patterns:
        if re.match(pattern, teacher_name, re.IGNORECASE):
            return False
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯åˆç†çš„å§“åæ ¼å¼
    # ä¸­æ–‡å§“åï¼š2-4ä¸ªä¸­æ–‡å­—ç¬¦
    # è‹±æ–‡å§“åï¼šå­—æ¯ã€ç©ºæ ¼ã€ç‚¹å·ç»„åˆ
    chinese_name_pattern = r'^[\u4e00-\u9fa5]{2,4}$'
    english_name_pattern = r'^[A-Za-z\s\.]{2,30}$'
    mixed_name_pattern = r'^[\u4e00-\u9fa5A-Za-z\s\.]{2,10}$'
    
    if not (re.match(chinese_name_pattern, teacher_name) or 
            re.match(english_name_pattern, teacher_name) or
            re.match(mixed_name_pattern, teacher_name)):
        return False
    
    return True


async def crawl_school_courses_with_auto_chunking(
    school_name: str,
    session_id: str
) -> List[Course]:
    """
    ğŸ”¥ å®Œå…¨ä½¿ç”¨ Crawl4ai è‡ªåŠ¨åˆ†å—çš„è¯¾ç¨‹æå–
    """
    print(f"\n{'='*80}")
    print(f"ğŸ« å¼€å§‹è‡ªåŠ¨åˆ†å—çˆ¬å–: {school_name}")
    print(f"ğŸ¤– ç­–ç•¥ï¼šå®Œæ•´é¡µé¢åŠ è½½ + Crawl4aiè‡ªåŠ¨åˆ†å— + LLMåˆ†æ")
    print(f"{'='*80}")
    
    search_url = build_school_search_url(school_name)
    print(f"ğŸ”— æœç´¢URL: {search_url}")
    
    # åˆ›å»ºç‹¬ç«‹çš„session ID
    unique_timestamp = int(time.time() * 1000)
    school_session_id = f"{session_id}_{school_name.replace(' ', '_').replace('/', '_').replace('ï¼ˆ', '_').replace('ï¼‰', '_')}_{unique_timestamp}"
    print(f"ğŸ†” Session ID: {school_session_id}")
    
    async with AsyncWebCrawler(config=get_browser_config()) as crawler:
        try:
            # ğŸ”¥ ç¬¬ä¸€æ­¥ï¼šå®Œæ•´é¡µé¢åŠ è½½
            print("ğŸš€ ç¬¬ä¸€æ­¥ï¼šåŠ è½½å®Œæ•´é¡µé¢å†…å®¹...")
            
            load_and_extract_js = f"""
            (async function() {{
                console.log('ğŸ”„ å¼€å§‹è‡ªåŠ¨åˆ†å—æ•°æ®åŠ è½½æµç¨‹...');
                
                let loadMoreAttempts = 0;
                let maxAttempts = {MAX_SCROLL_ATTEMPTS};
                let scrollDelay = {SCROLL_DELAY * 1000};
                let loadMoreDelay = {LOAD_MORE_DELAY * 1000};
                
                console.log('ğŸ“ å½“å‰URL:', window.location.href);
                console.log('ğŸ“„ é¡µé¢æ ‡é¢˜:', document.title);
                
                // ç­‰å¾…é¡µé¢å®Œå…¨åŠ è½½
                console.log('â³ ç­‰å¾…é¡µé¢å®Œå…¨åŠ è½½...');
                await new Promise(resolve => setTimeout(resolve, 8000));
                
                const initialDivCount = document.querySelectorAll('div').length;
                console.log(`ğŸ“Š åˆå§‹é¡µé¢å…ƒç´ : ${{initialDivCount}} ä¸ªdiv`);
                
                // æ•°æ®åŠ è½½å¾ªç¯
                const buttonSelectors = [
                    'button.text-white.bg-blue-600',
                    'button[class*="bg-blue-600"]',
                    'button[class*="text-white"]',
                    'button[class*="btn"]',
                    'button[class*="load"]',
                    'button[class*="more"]',
                    'a[class*="load"]',
                    'a[class*="more"]',
                    'button',
                    '.load-more',
                    '.loadmore',
                    '.show-more',
                    '[role="button"]'
                ];
                
                const loadMoreTexts = [
                    'åŠ è½½æ›´å¤š', 'æ›´å¤š', 'load more', 'æŸ¥çœ‹æ›´å¤š', 
                    'æ˜¾ç¤ºæ›´å¤š', 'show more', 'ç»§ç»­åŠ è½½', 
                    'continue', 'ä¸‹ä¸€é¡µ', 'next', 'å±•å¼€',
                    'expand', 'å…¨éƒ¨', 'all', 'æ›´å¤šè¯¾ç¨‹'
                ];
                
                while (loadMoreAttempts < maxAttempts) {{
                    console.log(`ğŸ”„ ç¬¬ ${{loadMoreAttempts + 1}} æ¬¡åŠ è½½å°è¯•`);
                    
                    // æ»šåŠ¨ç­–ç•¥
                    const scrollSteps = 5;
                    for (let step = 0; step < scrollSteps; step++) {{
                        const targetY = (document.body.scrollHeight / scrollSteps) * (step + 1);
                        window.scrollTo({{ top: targetY, behavior: 'smooth' }});
                        await new Promise(resolve => setTimeout(resolve, 1000));
                    }}
                    
                    window.scrollTo({{ top: document.body.scrollHeight, behavior: 'smooth' }});
                    await new Promise(resolve => setTimeout(resolve, scrollDelay));
                    
                    // æ™ºèƒ½æŒ‰é’®æŸ¥æ‰¾
                    let loadMoreButton = null;
                    
                    for (let selector of buttonSelectors) {{
                        try {{
                            const buttons = document.querySelectorAll(selector);
                            for (let btn of buttons) {{
                                const text = (btn.textContent || btn.innerText || '').trim().toLowerCase();
                                const isVisible = btn.offsetParent !== null && 
                                                window.getComputedStyle(btn).display !== 'none' &&
                                                window.getComputedStyle(btn).visibility !== 'hidden';
                                const isEnabled = !btn.disabled && !btn.classList.contains('disabled');
                                
                                const isLoadMore = loadMoreTexts.some(loadText => 
                                    text.includes(loadText.toLowerCase())
                                );
                                
                                if (isLoadMore && isVisible && isEnabled) {{
                                    loadMoreButton = btn;
                                    console.log(`ğŸ¯ æ‰¾åˆ°åŠ è½½æŒ‰é’®: "${{btn.textContent?.trim()}}" (é€‰æ‹©å™¨: ${{selector}})`);
                                    break;
                                }}
                            }}
                            if (loadMoreButton) break;
                        }} catch (e) {{
                            // å¿½ç•¥é€‰æ‹©å™¨é”™è¯¯ï¼Œç»§ç»­å°è¯•ä¸‹ä¸€ä¸ª
                        }}
                    }}
                    
                    if (loadMoreButton) {{
                        try {{
                            console.log('ğŸ”˜ å‡†å¤‡ç‚¹å‡»åŠ è½½æŒ‰é’®...');
                            
                            // ç¡®ä¿æŒ‰é’®å¯è§
                            loadMoreButton.scrollIntoView({{ 
                                behavior: 'smooth', 
                                block: 'center',
                                inline: 'center'
                            }});
                            await new Promise(resolve => setTimeout(resolve, 3000));
                            
                            const beforeClickElements = document.querySelectorAll('div').length;
                            
                            // å¤šç§ç‚¹å‡»æ–¹å¼
                            let clickSuccess = false;
                            
                            // æ–¹å¼1ï¼šç›´æ¥ç‚¹å‡»
                            try {{
                                loadMoreButton.click();
                                clickSuccess = true;
                                console.log('âœ… ç›´æ¥ç‚¹å‡»æˆåŠŸ');
                            }} catch (e) {{
                                console.log('âš ï¸ ç›´æ¥ç‚¹å‡»å¤±è´¥ï¼Œå°è¯•äº‹ä»¶è§¦å‘');
                                
                                // æ–¹å¼2ï¼šäº‹ä»¶è§¦å‘
                                try {{
                                    const clickEvent = new MouseEvent('click', {{
                                        bubbles: true,
                                        cancelable: true,
                                        view: window
                                    }});
                                    loadMoreButton.dispatchEvent(clickEvent);
                                    clickSuccess = true;
                                    console.log('âœ… äº‹ä»¶è§¦å‘ç‚¹å‡»æˆåŠŸ');
                                }} catch (e2) {{
                                    console.log('âŒ æ‰€æœ‰ç‚¹å‡»æ–¹å¼éƒ½å¤±è´¥');
                                }}
                            }}
                            
                            if (clickSuccess) {{
                                console.log('ğŸ• ç­‰å¾…å†…å®¹åŠ è½½...');
                                await new Promise(resolve => setTimeout(resolve, loadMoreDelay));
                                
                                const afterClickElements = document.querySelectorAll('div').length;
                                const addedElements = afterClickElements - beforeClickElements;
                                
                                console.log(`ğŸ“ˆ ç‚¹å‡»åå…ƒç´ å˜åŒ–: ${{beforeClickElements}} -> ${{afterClickElements}} (+${{addedElements}})`);
                                
                                if (addedElements <= 0) {{
                                    console.log('âš ï¸ æ²¡æœ‰æ–°å¢å†…å®¹ï¼Œå¯èƒ½å·²å…¨éƒ¨åŠ è½½');
                                    break;
                                }}
                            }} else {{
                                console.log('âŒ æ‰€æœ‰ç‚¹å‡»æ–¹å¼éƒ½å¤±è´¥');
                                break;
                            }}
                            
                            loadMoreAttempts++;
                        }} catch (error) {{
                            console.log('âŒ ç‚¹å‡»æŒ‰é’®è¿‡ç¨‹ä¸­å‡ºé”™:', error);
                            break;
                        }}
                    }} else {{
                        console.log('âœ… æœªæ‰¾åˆ°æ›´å¤šåŠ è½½æŒ‰é’®ï¼Œæ•°æ®å¯èƒ½å·²å…¨éƒ¨åŠ è½½');
                        break;
                    }}
                    
                    await new Promise(resolve => setTimeout(resolve, 2000));
                }}
                
                const finalDivCount = document.querySelectorAll('div').length;
                console.log(`ğŸ“Š æ•°æ®åŠ è½½å®Œæˆç»Ÿè®¡:`);
                console.log(`  åˆå§‹å…ƒç´ : ${{initialDivCount}}`);
                console.log(`  æœ€ç»ˆå…ƒç´ : ${{finalDivCount}}`);
                console.log(`  æ€»å…±åŠ è½½: ${{finalDivCount - initialDivCount}} ä¸ªå…ƒç´ `);
                console.log(`  åŠ è½½å°è¯•æ¬¡æ•°: ${{loadMoreAttempts}}`);
                
                // æœ€ç»ˆç¡®ä¿é¡µé¢å†…å®¹å®Œå…¨å¯è§
                window.scrollTo(0, 0);
                await new Promise(resolve => setTimeout(resolve, 2000));
                window.scrollTo(0, document.body.scrollHeight);
                await new Promise(resolve => setTimeout(resolve, 4000));
                
                console.log('ğŸ‰ é¡µé¢å®Œæ•´æ€§åŠ è½½å®Œæˆï¼Œå‡†å¤‡è‡ªåŠ¨åˆ†å—LLMåˆ†æ');
                
                return {{
                    success: true,
                    loadAttempts: loadMoreAttempts,
                    initialElements: initialDivCount,
                    finalElements: finalDivCount,
                    elementsAdded: finalDivCount - initialDivCount,
                    message: 'é¡µé¢å†…å®¹å·²å…¨éƒ¨åŠ è½½ï¼Œå‡†å¤‡è‡ªåŠ¨åˆ†å—æå–'
                }};
            }})();
            """
            
            # ğŸ”¥ ç¬¬äºŒæ­¥ï¼šåˆ›å»ºè‡ªåŠ¨åˆ†å—LLMç­–ç•¥
            print("ğŸ¤– ç¬¬äºŒæ­¥ï¼šåˆ›å»ºè‡ªåŠ¨åˆ†å—LLMç­–ç•¥...")
            llm_strategy = create_auto_chunking_llm_strategy(school_name)
            
            # ğŸ”¥ ç¬¬ä¸‰æ­¥ï¼šç›´æ¥ä½¿ç”¨è‡ªåŠ¨åˆ†å—è¿›è¡ŒLLMåˆ†æ
            print("âš¡ ç¬¬ä¸‰æ­¥ï¼šä½¿ç”¨Crawl4aiè‡ªåŠ¨åˆ†å—è¿›è¡ŒLLMåˆ†æ...")
            
            result = await crawler.arun(
                url=search_url,
                config=CrawlerRunConfig(
                    cache_mode=CacheMode.BYPASS,
                    session_id=school_session_id,
                    js_code=load_and_extract_js,
                    
                    # ğŸ”¥ å…³é”®ï¼šæ·»åŠ è‡ªåŠ¨åˆ†å—LLMç­–ç•¥
                    extraction_strategy=llm_strategy,
                    
                    delay_before_return_html=180.0,
                    wait_for_images=False,
                    page_timeout=150000,  # å¢åŠ è¶…æ—¶æ—¶é—´åˆ°2.5åˆ†é’Ÿ
                    override_navigator=True,
                ),
            )
            
            if not result.success:
                print(f"âŒ é¡µé¢åŠ è½½å¤±è´¥: {result.error_message}")
                return []
            
            print(f"âœ… é¡µé¢åŠ è½½æˆåŠŸï¼ŒHTMLé•¿åº¦: {len(result.cleaned_html):,} å­—ç¬¦")
            
            # ğŸ”¥ ç¬¬å››æ­¥ï¼šå¤„ç†è‡ªåŠ¨åˆ†å—LLMæå–ç»“æœ
            print("ğŸ“Š ç¬¬å››æ­¥ï¼šå¤„ç†è‡ªåŠ¨åˆ†å—LLMæå–ç»“æœ...")
            
            if result.extracted_content:
                try:
                    print(f"ğŸ” LLMæå–åŸå§‹ç»“æœé•¿åº¦: {len(result.extracted_content):,} å­—ç¬¦")
                    print(f"ğŸ” LLMæå–å†…å®¹é¢„è§ˆ: {result.extracted_content[:200]}...")
                    
                    # è§£æLLMæå–çš„ç»“æœ
                    extracted_data = json.loads(result.extracted_content)
                    
                    # ç¡®ä¿ç»“æœæ˜¯åˆ—è¡¨æ ¼å¼
                    if isinstance(extracted_data, dict):
                        if 'courses' in extracted_data:
                            course_list = extracted_data['courses']
                        elif 'data' in extracted_data:
                            course_list = extracted_data['data']
                        else:
                            # å¯èƒ½æ˜¯å…¶ä»–åŒ…è£…æ ¼å¼ï¼Œå°è¯•è·å–ç¬¬ä¸€ä¸ªåˆ—è¡¨å€¼
                            for value in extracted_data.values():
                                if isinstance(value, list):
                                    course_list = value
                                    break
                            else:
                                print(f"âš ï¸ æ— æ³•è¯†åˆ«çš„æå–ç»“æœæ ¼å¼: {extracted_data}")
                                course_list = []
                    elif isinstance(extracted_data, list):
                        course_list = extracted_data
                    else:
                        print(f"âš ï¸ æ„å¤–çš„LLMè¿”å›æ ¼å¼: {type(extracted_data)}")
                        course_list = []
                    
                    print(f"ğŸ“‹ è§£æå¾—åˆ° {len(course_list)} ä¸ªè¯¾ç¨‹æ¡ç›®")
                    
                    # ğŸ”¥ å¤„ç†æå–çš„è¯¾ç¨‹æ•°æ®
                    all_courses = []
                    for i, course_data in enumerate(course_list):
                        if isinstance(course_data, dict):
                            course_name = course_data.get('course', '').strip()
                            teacher = course_data.get('teacher', '').strip()
                            
                            # éªŒè¯æ•°æ®è´¨é‡
                            if course_name and teacher:
                                if validate_course_data(course_data):
                                    course = Course(
                                        school=school_name,
                                        course_name=course_name,
                                        teacher=teacher
                                    )
                                    all_courses.append(course)
                                    print(f"  âœ… æå– {i+1}: {course_name} - {teacher}")
                                else:
                                    print(f"  âŒ éªŒè¯å¤±è´¥ {i+1}: {course_name} - {teacher}")
                            else:
                                print(f"  âš ï¸ æ•°æ®ä¸å®Œæ•´ {i+1}: course='{course_name}', teacher='{teacher}'")
                        else:
                            print(f"  âš ï¸ éå­—å…¸æ ¼å¼çš„æ•°æ® {i+1}: {course_data}")
                    
                    # ğŸ”¥ å»é‡å¤„ç†
                    unique_courses = []
                    seen_courses = set()
                    
                    for course in all_courses:
                        course_key = f"{course.course_name.strip().lower()}_{course.teacher.strip().lower()}"
                        if course_key not in seen_courses:
                            seen_courses.add(course_key)
                            unique_courses.append(course)
                        else:
                            print(f"ğŸ”„ å»é‡: {course.course_name} - {course.teacher}")
                    
                    print(f"ğŸ‰ è‡ªåŠ¨åˆ†å—LLMåˆ†æå®Œæˆ!")
                    print(f"  ğŸ“š æå–è¯¾ç¨‹æ€»æ•°: {len(all_courses)}")
                    print(f"  âœ¨ å»é‡åè¯¾ç¨‹æ•°: {len(unique_courses)}")
                    
                    # æ˜¾ç¤ºæ ·ä¾‹
                    if unique_courses:
                        print("ğŸ“š æå–çš„è¯¾ç¨‹æ ·ä¾‹:")
                        for i, course in enumerate(unique_courses[:15], 1):
                            print(f"  {i}. {course.course_name} - {course.teacher}")
                        if len(unique_courses) > 15:
                            print(f"  ... è¿˜æœ‰ {len(unique_courses) - 15} é—¨è¯¾ç¨‹")
                    else:
                        print("âš ï¸ å»é‡åæ²¡æœ‰æœ‰æ•ˆè¯¾ç¨‹")
                        
                        # å¦‚æœæ²¡æœ‰ç»“æœï¼Œä¿å­˜åŸå§‹HTMLç”¨äºè°ƒè¯•
                        debug_file = f"debug_no_results_{school_name}_{int(time.time())}.html"
                        with open(debug_file, 'w', encoding='utf-8') as f:
                            f.write(result.cleaned_html)
                        print(f"ğŸ” åŸå§‹HTMLå·²ä¿å­˜åˆ°: {debug_file}")
                        
                        debug_extract_file = f"debug_extract_{school_name}_{int(time.time())}.json"
                        with open(debug_extract_file, 'w', encoding='utf-8') as f:
                            f.write(result.extracted_content)
                        print(f"ğŸ” LLMæå–ç»“æœå·²ä¿å­˜åˆ°: {debug_extract_file}")
                    
                    # ğŸ”¥ æ˜¾ç¤ºLLMä½¿ç”¨ç»Ÿè®¡
                    try:
                        if hasattr(llm_strategy, 'show_usage'):
                            llm_strategy.show_usage()
                    except Exception as e:
                        print(f"ğŸ“Š LLMä½¿ç”¨ç»Ÿè®¡è·å–å¤±è´¥: {e}")
                    
                    return unique_courses
                    
                except json.JSONDecodeError as e:
                    print(f"âŒ JSONè§£æå¤±è´¥: {e}")
                    print(f"åŸå§‹æå–å†…å®¹: {result.extracted_content[:1000]}...")
                    
                    # ä¿å­˜è§£æå¤±è´¥çš„å†…å®¹ç”¨äºè°ƒè¯•
                    error_file = f"debug_json_error_{school_name}_{int(time.time())}.txt"
                    with open(error_file, 'w', encoding='utf-8') as f:
                        f.write(f"JSONè§£æé”™è¯¯: {e}\n\n")
                        f.write(f"åŸå§‹æå–å†…å®¹:\n{result.extracted_content}")
                    print(f"ğŸ” è§£æé”™è¯¯è¯¦æƒ…å·²ä¿å­˜åˆ°: {error_file}")
                    
                    return []
                    
            else:
                print("âŒ LLMæœªæå–åˆ°ä»»ä½•å†…å®¹")
                
                # ä¿å­˜åŸå§‹HTMLç”¨äºè°ƒè¯•
                debug_file = f"debug_empty_extract_{school_name}_{int(time.time())}.html"
                with open(debug_file, 'w', encoding='utf-8') as f:
                    f.write(result.cleaned_html)
                print(f"ğŸ” åŸå§‹HTMLå·²ä¿å­˜åˆ°: {debug_file}")
                
                return []
            
        except Exception as e:
            print(f"âŒ {school_name} è‡ªåŠ¨åˆ†å—çˆ¬å–å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            return []


# ğŸ”¥ ä¸»è¦å‡½æ•°ï¼šçˆ¬å–å•ä¸ªå­¦æ ¡çš„è¯¾ç¨‹ä¿¡æ¯
async def crawl_school_courses(
    school_name: str,
    session_id: str
) -> List[Course]:
    """
    çˆ¬å–å•ä¸ªå­¦æ ¡çš„æ‰€æœ‰è¯¾ç¨‹ä¿¡æ¯ - ä½¿ç”¨è‡ªåŠ¨åˆ†å—
    """
    print(f"ğŸ¯ å¼€å§‹çˆ¬å–å­¦æ ¡: {school_name}")
    print(f"ğŸ†” Session ID: {session_id}")
    
    try:
        return await crawl_school_courses_with_auto_chunking(school_name, session_id)
    except Exception as e:
        print(f"âŒ çˆ¬å– {school_name} å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return []


# ğŸ”¥ å¤šå­¦æ ¡çˆ¬å–å‡½æ•°
async def crawl_multiple_schools_with_recovery(
    school_names: List[str],
    session_base_id: str = "multi_school_auto"
) -> dict:
    """
    ğŸ« çˆ¬å–å¤šä¸ªå­¦æ ¡çš„è¯¾ç¨‹ä¿¡æ¯ - ä½¿ç”¨è‡ªåŠ¨åˆ†å—
    """
    results = {}
    
    for i, school_name in enumerate(school_names):
        print(f"\nğŸ¯ å¤„ç†å­¦æ ¡ {i+1}/{len(school_names)}: {school_name}")
        
        max_retries = 2
        for retry in range(max_retries):
            try:
                # æ¯ä¸ªå­¦æ ¡ä½¿ç”¨ç‹¬ç«‹çš„session
                session_id = f"{session_base_id}_{i}_{int(time.time())}"
                
                courses = await crawl_school_courses_with_auto_chunking(school_name, session_id)
                
                results[school_name] = courses
                print(f"âœ… {school_name}: æˆåŠŸè·å– {len(courses)} é—¨è¯¾ç¨‹")
                
                # æˆåŠŸåç¨ä½œä¼‘æ¯ï¼Œé¿å…è¿‡äºé¢‘ç¹çš„è¯·æ±‚
                await asyncio.sleep(3)
                break
                
            except Exception as e:
                print(f"âŒ {school_name} ç¬¬ {retry+1} æ¬¡å°è¯•å¤±è´¥: {e}")
                
                if retry < max_retries - 1:
                    print(f"ğŸ”„ {school_name} å°†è¿›è¡Œç¬¬ {retry+2} æ¬¡é‡è¯•...")
                    await asyncio.sleep(5)
                else:
                    print(f"ğŸ’€ {school_name}: æ‰€æœ‰é‡è¯•å‡å¤±è´¥")
                    results[school_name] = []
    
    return results


# ğŸ”¥ æµ‹è¯•å‡½æ•°
async def test_auto_chunking_extraction(
    school_name: str,
    session_id: str
) -> None:
    """
    æµ‹è¯•è‡ªåŠ¨åˆ†å—LLMæå–åŠŸèƒ½
    """
    print(f"ğŸ§ª å¼€å§‹æµ‹è¯•è‡ªåŠ¨åˆ†å—æå–åŠŸèƒ½: {school_name}")
    
    courses = await crawl_school_courses_with_auto_chunking(school_name, session_id)
    
    print(f"\n{'='*50}")
    print(f"ğŸ“Š æµ‹è¯•ç»“æœç»Ÿè®¡:")
    print(f"  å­¦æ ¡: {school_name}")
    print(f"  æå–è¯¾ç¨‹æ•°: {len(courses)}")
    print(f"{'='*50}")
    
    if courses:
        print("ğŸ“ æå–çš„è¯¾ç¨‹è¯¦æƒ…:")
        for i, course in enumerate(courses[:20], 1):  # æ˜¾ç¤ºå‰20ä¸ª
            print(f"  {i}. {course.course_name} - {course.teacher}")
        if len(courses) > 20:
            print(f"  ... è¿˜æœ‰ {len(courses) - 20} é—¨è¯¾ç¨‹")
    else:
        print("âš ï¸ æœªæå–åˆ°ä»»ä½•è¯¾ç¨‹")


# ğŸ”¥ è°ƒè¯•å‡½æ•°
async def debug_page_structure(
    url: str,
    session_id: str
) -> None:
    """
    è°ƒè¯•é¡µé¢ç»“æ„ï¼ŒæŸ¥çœ‹å®é™…çš„HTMLå†…å®¹
    """
    print(f"ğŸ” å¼€å§‹è°ƒè¯•é¡µé¢ç»“æ„: {url}")
    
    debug_js = """
    (async function() {
        console.log('ğŸ” å¼€å§‹é¡µé¢ç»“æ„è°ƒè¯•...');
        
        await new Promise(resolve => setTimeout(resolve, 5000));
        
        // ç»Ÿè®¡å„ç§å…ƒç´ 
        const stats = {
            'total_divs': document.querySelectorAll('div').length,
            'course_keywords': document.body.textContent.toLowerCase().split('è¯¾ç¨‹').length - 1,
            'teacher_keywords': document.body.textContent.toLowerCase().split('æ•™å¸ˆ').length - 1,
            'articles': document.querySelectorAll('article').length,
            'sections': document.querySelectorAll('section').length,
            'lists': document.querySelectorAll('ul, ol').length,
            'buttons': document.querySelectorAll('button').length,
            'text_length': document.body.textContent.length
        };
        
        console.log('ğŸ“Š é¡µé¢å…ƒç´ ç»Ÿè®¡:', stats);
        
        return { success: true, stats: stats };
    })();
    """
    
    async with AsyncWebCrawler(config=get_browser_config()) as crawler:
        try:
            result = await crawler.arun(
                url=url,
                config=CrawlerRunConfig(
                    cache_mode=CacheMode.BYPASS,
                    session_id=session_id,
                    js_code=debug_js,
                    delay_before_return_html=15.0,
                ),
            )
            
            if result.success:
                print("âœ… é¡µé¢ç»“æ„è°ƒè¯•å®Œæˆ")
                
                # ä¿å­˜HTMLåˆ°æ–‡ä»¶ç”¨äºåˆ†æ
                debug_file = f"debug_structure_{session_id}.html"
                with open(debug_file, 'w', encoding='utf-8') as f:
                    f.write(result.cleaned_html)
                print(f"ğŸ“ é¡µé¢HTMLå·²ä¿å­˜åˆ°: {debug_file}")
                
                # åˆ†æé¡µé¢å†…å®¹
                from bs4 import BeautifulSoup
                soup = BeautifulSoup(result.cleaned_html, 'html.parser')
                text = soup.get_text()
                
                course_count = text.lower().count('è¯¾ç¨‹')
                teacher_count = text.lower().count('æ•™å¸ˆ') + text.lower().count('è®²å¸ˆ') + text.lower().count('è€å¸ˆ')
                
                print(f"ğŸ“Š é¡µé¢å†…å®¹åˆ†æ:")
                print(f"  è¯¾ç¨‹ç›¸å…³è¯æ±‡å‡ºç°æ¬¡æ•°: {course_count}")
                print(f"  æ•™å¸ˆç›¸å…³è¯æ±‡å‡ºç°æ¬¡æ•°: {teacher_count}")
                print(f"  é¡µé¢æ–‡æœ¬é•¿åº¦: {len(text):,} å­—ç¬¦")
                
            else:
                print(f"âŒ é¡µé¢ç»“æ„è°ƒè¯•å¤±è´¥: {result.error_message}")
                
        except Exception as e:
            print(f"âŒ è°ƒè¯•å¼‚å¸¸: {e}")


# ğŸ”¥ å…¼å®¹æ€§å‡½æ•°ï¼ˆå¦‚æœæœ‰å…¶ä»–åœ°æ–¹è°ƒç”¨æ—§ç‰ˆæœ¬å‡½æ•°ï¼‰
async def crawl_school_courses_with_llm(
    school_name: str,
    session_id: str
) -> List[Course]:
    """
    å…¼å®¹æ—§ç‰ˆæœ¬çš„å‡½æ•°å - é‡å®šå‘åˆ°è‡ªåŠ¨åˆ†å—ç‰ˆæœ¬
    """
    print("âš ï¸ æ£€æµ‹åˆ°æ—§ç‰ˆæœ¬å‡½æ•°è°ƒç”¨ï¼Œé‡å®šå‘åˆ°è‡ªåŠ¨åˆ†å—ç‰ˆæœ¬")
    return await crawl_school_courses_with_auto_chunking(school_name, session_id)


# åºŸå¼ƒçš„å‡½æ•°ï¼ˆä¿ç•™ä»¥é˜²å…¶ä»–åœ°æ–¹è°ƒç”¨ï¼‰
def smart_chunk_content(html_content: str, chunk_size: int = 20000) -> List[str]:
    """
    âš ï¸ æ­¤å‡½æ•°å·²åºŸå¼ƒï¼Œç°åœ¨ä½¿ç”¨Crawl4aiè‡ªåŠ¨åˆ†å—
    """
    print("âš ï¸ è­¦å‘Šï¼šæ‰‹åŠ¨æ™ºèƒ½åˆ†ç‰‡å·²åºŸå¼ƒï¼Œç°åœ¨ä½¿ç”¨Crawl4aiè‡ªåŠ¨åˆ†å—")
    return []


def create_llm_extraction_strategy(school_name: str):
    """
    âš ï¸ æ­¤å‡½æ•°å·²åºŸå¼ƒï¼Œç°åœ¨ä½¿ç”¨create_auto_chunking_llm_strategy
    """
    print("âš ï¸ è­¦å‘Šï¼šæ—§ç‰ˆLLMç­–ç•¥å·²åºŸå¼ƒï¼Œé‡å®šå‘åˆ°è‡ªåŠ¨åˆ†å—ç‰ˆæœ¬")
    return create_auto_chunking_llm_strategy(school_name)


async def process_chunk_with_llm(*args, **kwargs):
    """
    âš ï¸ æ­¤å‡½æ•°å·²åºŸå¼ƒï¼Œç°åœ¨ä½¿ç”¨Crawl4aiè‡ªåŠ¨åˆ†å—
    """
    print("âš ï¸ è­¦å‘Šï¼šæ‰‹åŠ¨åˆ†ç‰‡å¤„ç†å·²åºŸå¼ƒï¼Œç°åœ¨ä½¿ç”¨Crawl4aiè‡ªåŠ¨åˆ†å—")
    return []


def get_course_container_selector() -> str:
    """
    âš ï¸ æ­¤å‡½æ•°å·²åºŸå¼ƒï¼Œç°åœ¨ä½¿ç”¨LLMè‡ªåŠ¨åˆ†å—æå–
    """
    print("âš ï¸ è­¦å‘Šï¼šCSSé€‰æ‹©å™¨æ–¹å¼å·²åºŸå¼ƒï¼Œç°åœ¨ä½¿ç”¨LLMè‡ªåŠ¨åˆ†å—æå–")
    return "ä½¿ç”¨LLMè‡ªåŠ¨åˆ†å—æå–ï¼Œæ— éœ€CSSé€‰æ‹©å™¨"