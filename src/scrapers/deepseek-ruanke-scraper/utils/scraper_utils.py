import json
import os
from typing import List, Set, Tuple

from crawl4ai import (
    AsyncWebCrawler,
    BrowserConfig,
    CacheMode,
    CrawlerRunConfig,
    LLMExtractionStrategy,
)

from models.venue import Venue
from utils.data_utils import is_complete_venue, is_duplicate_venue


def get_browser_config() -> BrowserConfig:
    """
    Returns the browser configuration for the crawler.

    Returns:
        BrowserConfig: The configuration settings for the browser.
    """
    # https://docs.crawl4ai.com/core/browser-crawler-config/
    return BrowserConfig(
        browser_type="chromium",  # Type of browser to simulate
        headless=False,  # Whether to run in headless mode (no GUI)
        verbose=True,  # Enable verbose logging
    )


def get_llm_strategy() -> LLMExtractionStrategy:
    """
    Returns the configuration for the language model extraction strategy.

    Returns:
        LLMExtractionStrategy: The settings for how to extract data using LLM.
    """
    # https://docs.crawl4ai.com/api/strategies/#llmextractionstrategy
    return LLMExtractionStrategy(
        provider="groq/deepseek-r1-distill-llama-70b",  # Name of the LLM provider
        api_token=os.getenv("GROQ_API_KEY"),  # API token for authentication
        schema=Venue.model_json_schema(),  # JSON schema of the data model
        extraction_type="schema",  # Type of extraction to perform
        instruction=(
            "Extract university ranking data from the table. "
            "For each university, extract: "
            "1. name: the university name "
            "2. layer: the percentage layer/tier information (like 'å‰1%', 'å‰5%', etc.) "
            "Look for span elements containing percentage information that indicates which tier the university belongs to. "
            "The layer field should contain the percentage range like 'å‰1%' or 'å‰5%' etc. "
            "Return as JSON array with objects containing 'name' and 'layer' fields."
        ),  # Instructions for the LLM
        input_format="markdown",  # Format of the input content
        verbose=True,  # Enable verbose logging
    )


async def check_no_results(
    crawler: AsyncWebCrawler,
    url: str,
    session_id: str,
) -> bool:
    """
    Checks if the "No Results Found" message is present on the page.

    Args:
        crawler (AsyncWebCrawler): The web crawler instance.
        url (str): The URL to check.
        session_id (str): The session identifier.

    Returns:
        bool: True if "No Results Found" message is found, False otherwise.
    """
    # Fetch the page without any CSS selector or extraction strategy
    result = await crawler.arun(
        url=url,
        config=CrawlerRunConfig(
            cache_mode=CacheMode.BYPASS,
            session_id=session_id,
            delay_before_return_html=2.0,
        ),
    )

    if result.success:
        if "No Results Found" in result.cleaned_html:
            return True
    else:
        print(
            f"Error fetching page for 'No Results Found' check: {result.error_message}"
        )

    return False


async def fetch_and_process_page(
    crawler: AsyncWebCrawler,
    page_number: int,
    base_url: str,
    subject_name: str,  # ğŸ”¥ æ–°å¢ï¼šå­¦ç§‘åå‚æ•° ğŸ”¥
    css_selector: str,
    llm_strategy: LLMExtractionStrategy,
    session_id: str,
    required_keys: List[str],
    seen_names: Set[str],
) -> Tuple[List[dict], bool]:
    """
    Fetches and processes a single page of venue data.

    Args:
        crawler (AsyncWebCrawler): The web crawler instance.
        page_number (int): The page number to fetch.
        base_url (str): The base URL of the website.
        css_selector (str): The CSS selector to target the content.
        llm_strategy (LLMExtractionStrategy): The LLM extraction strategy.
        session_id (str): The session identifier.
        required_keys (List[str]): List of required keys in the venue data.
        seen_names (Set[str]): Set of venue names that have already been seen.

    Returns:
        Tuple[List[dict], bool]:
            - List[dict]: A list of processed venues from the page.
            - bool: A flag indicating if the "No Results Found" message was encountered.
    """
    # ğŸ”¥ ä¿®æ”¹è¿™éƒ¨åˆ†ï¼šä¸å†ä½¿ç”¨URLå‚æ•°ï¼Œè€Œæ˜¯é€šè¿‡é¡µç è·³è½¬ ğŸ”¥
    if page_number == 1:
        # ç¬¬ä¸€é¡µç›´æ¥è®¿é—®åŸå§‹URL
        url = base_url
        print(f" åŠ è½½ {subject_name} ç¬¬ {page_number} é¡µ...")
        
        # ç¬¬ä¸€é¡µä¸éœ€è¦é¢å¤–æ“ä½œ
        page_navigation_js = """
        console.log('ç¬¬ä¸€é¡µï¼Œæ— éœ€è·³è½¬');
        await new Promise(resolve => setTimeout(resolve, 2000));
        """
    else:
        # ç¬¬äºŒé¡µåŠä»¥åï¼Œä½¿ç”¨ç›¸åŒURLä½†é€šè¿‡JavaScriptè¾“å…¥é¡µç è·³è½¬
        url = base_url  # URLä¿æŒä¸å˜
        print(f"Navigating to page {page_number} via quick jumper...")
        
        # ğŸ”¥ å…³é”®ï¼šé¡µç è·³è½¬çš„JavaScriptä»£ç  ğŸ”¥
        # å°†è¿™éƒ¨åˆ†JavaScriptä»£ç æ›¿æ¢ä¸ºæ›´å¼ºå¤§çš„ç‰ˆæœ¬ï¼š
        page_navigation_js = f"""
        console.log('å¼€å§‹è·³è½¬åˆ°ç¬¬ {page_number} é¡µ...');

        // ç­‰å¾…é¡µé¢åŠ è½½
        await new Promise(resolve => setTimeout(resolve, 3000));

        // æŸ¥æ‰¾å¿«é€Ÿè·³è½¬å®¹å™¨
        const quickJumper = document.querySelector('.ant-pagination-options-quick-jumper');

        if (quickJumper) {{
            console.log('âœ… æ‰¾åˆ°å¿«é€Ÿè·³è½¬å®¹å™¨');
            
            // æŸ¥æ‰¾è¾“å…¥æ¡†
            const pageInput = quickJumper.querySelector('input');
            
            if (pageInput) {{
                console.log('âœ… æ‰¾åˆ°é¡µç è¾“å…¥æ¡†');
                console.log('è¾“å…¥æ¡†å½“å‰å€¼:', pageInput.value);
                
                // ğŸ”¥ æ–¹æ³•1: å®Œæ•´çš„è¾“å…¥å’Œäº‹ä»¶åºåˆ— ğŸ”¥
                pageInput.focus();
                pageInput.select();  // é€‰ä¸­æ‰€æœ‰æ–‡æœ¬
                pageInput.value = '';  // æ¸…ç©º
                
                // é€å­—ç¬¦è¾“å…¥ï¼ˆæ¨¡æ‹ŸçœŸå®è¾“å…¥ï¼‰
                const targetValue = '{page_number}';
                for(let i = 0; i < targetValue.length; i++) {{
                    pageInput.value += targetValue[i];
                    
                    // è§¦å‘æ¯ä¸ªå­—ç¬¦çš„è¾“å…¥äº‹ä»¶
                    pageInput.dispatchEvent(new InputEvent('input', {{ 
                        bubbles: true, 
                        data: targetValue[i] 
                    }}));
                    
                    await new Promise(resolve => setTimeout(resolve, 50));
                }}
                
                console.log('ğŸ“ å·²è¾“å…¥é¡µç :', pageInput.value);
                
                // ğŸ”¥ è§¦å‘å¤šç§äº‹ä»¶ç¡®ä¿è¢«æ£€æµ‹åˆ° ğŸ”¥
                
                // 1. è§¦å‘ input äº‹ä»¶
                pageInput.dispatchEvent(new Event('input', {{ bubbles: true }}));
                
                // 2. è§¦å‘ change äº‹ä»¶
                pageInput.dispatchEvent(new Event('change', {{ bubbles: true }}));
                
                // 3. è§¦å‘ keyup äº‹ä»¶
                pageInput.dispatchEvent(new KeyboardEvent('keyup', {{
                    key: '{page_number}',
                    bubbles: true
                }}));
                
                await new Promise(resolve => setTimeout(resolve, 500));
                
                // ğŸ”¥ æ–¹æ³•2: å°è¯•å¤šç§å›è½¦æ–¹å¼ ğŸ”¥
                
                // 1. keydownäº‹ä»¶
                const keydownEvent = new KeyboardEvent('keydown', {{
                    key: 'Enter',
                    code: 'Enter',
                    keyCode: 13,
                    which: 13,
                    bubbles: true,
                    cancelable: true
                }});
                pageInput.dispatchEvent(keydownEvent);
                console.log('âŒ¨ï¸ è§¦å‘keydown Enter');
                
                await new Promise(resolve => setTimeout(resolve, 200));
                
                // 2. keypressäº‹ä»¶
                const keypressEvent = new KeyboardEvent('keypress', {{
                    key: 'Enter',
                    code: 'Enter',
                    keyCode: 13,
                    which: 13,
                    bubbles: true,
                    cancelable: true
                }});
                pageInput.dispatchEvent(keypressEvent);
                console.log('âŒ¨ï¸ è§¦å‘keypress Enter');
                
                await new Promise(resolve => setTimeout(resolve, 200));
                
                // 3. keyupäº‹ä»¶
                const keyupEvent = new KeyboardEvent('keyup', {{
                    key: 'Enter',
                    code: 'Enter',
                    keyCode: 13,
                    which: 13,
                    bubbles: true
                }});
                pageInput.dispatchEvent(keyupEvent);
                console.log('âŒ¨ï¸ è§¦å‘keyup Enter');
                
                await new Promise(resolve => setTimeout(resolve, 500));
                
                // ğŸ”¥ æ–¹æ³•3: æŸ¥æ‰¾å¹¶ç‚¹å‡»ç¡®è®¤æŒ‰é’® ğŸ”¥
                const confirmButtons = quickJumper.querySelectorAll('button, .ant-btn');
                console.log(`æ‰¾åˆ° ${{confirmButtons.length}} ä¸ªå¯èƒ½çš„ç¡®è®¤æŒ‰é’®`);
                
                for(let btn of confirmButtons) {{
                    if(btn.offsetParent !== null && !btn.disabled) {{
                        console.log('ğŸ”˜ ç‚¹å‡»ç¡®è®¤æŒ‰é’®:', btn.textContent.trim());
                        btn.click();
                        break;
                    }}
                }}
                
                await new Promise(resolve => setTimeout(resolve, 1000));
                
                // ğŸ”¥ æ–¹æ³•4: è§¦å‘è¡¨å•æäº¤ï¼ˆå¦‚æœè¾“å…¥æ¡†åœ¨è¡¨å•ä¸­ï¼‰ ğŸ”¥
                const form = pageInput.closest('form');
                if(form) {{
                    console.log('ğŸ“‹ æ‰¾åˆ°è¡¨å•ï¼Œè§¦å‘æäº¤');
                    form.dispatchEvent(new Event('submit', {{ bubbles: true }}));
                }}
                
                // ğŸ”¥ æ–¹æ³•5: å°è¯•é€šè¿‡React/Vueç»„ä»¶è§¦å‘ ğŸ”¥
                if(pageInput._reactInternalFiber || pageInput.__reactInternalInstance) {{
                    console.log('ğŸ”„ æ£€æµ‹åˆ°Reactç»„ä»¶ï¼Œå°è¯•Reactäº‹ä»¶');
                    const nativeInputValueSetter = Object.getOwnPropertyDescriptor(window.HTMLInputElement.prototype, 'value').set;
                    nativeInputValueSetter.call(pageInput, '{page_number}');
                    
                    const reactEvent = new Event('input', {{ bubbles: true }});
                    reactEvent.simulated = true;
                    pageInput.dispatchEvent(reactEvent);
                }}
                
                // ç­‰å¾…é¡µé¢è·³è½¬
                console.log('â³ ç­‰å¾…é¡µé¢è·³è½¬...');
                await new Promise(resolve => setTimeout(resolve, 4000));
                
                // ğŸ”¥ éªŒè¯æ˜¯å¦è·³è½¬æˆåŠŸ ğŸ”¥
                const currentPageIndicator = document.querySelector('.ant-pagination-item-active');
                if(currentPageIndicator) {{
                    const currentPage = currentPageIndicator.textContent.trim();
                    console.log('ğŸ“„ å½“å‰é¡µç æŒ‡ç¤ºå™¨æ˜¾ç¤º:', currentPage);
                    
                    if(currentPage === '{page_number}') {{
                        console.log('âœ… é¡µé¢è·³è½¬æˆåŠŸ!');
                    }} else {{
                        console.log('âŒ é¡µé¢è·³è½¬å¯èƒ½å¤±è´¥ï¼ŒæœŸæœ›:', '{page_number}', 'å®é™…:', currentPage);
                    }}
                }} else {{
                    console.log('âš ï¸ æœªæ‰¾åˆ°å½“å‰é¡µç æŒ‡ç¤ºå™¨');
                }}
                
            }} else {{
                console.log('âŒ æœªæ‰¾åˆ°è¾“å…¥æ¡†');
                
                // ğŸ”¥ å¤‡é€‰æ–¹æ¡ˆï¼šæŸ¥æ‰¾å…¶ä»–å¯èƒ½çš„è¾“å…¥æ¡† ğŸ”¥
                const allInputs = document.querySelectorAll('input[type="number"], input[type="text"]');
                console.log(`æ‰¾åˆ° ${{allInputs.length}} ä¸ªè¾“å…¥æ¡†`);
                
                for(let input of allInputs) {{
                    if(input.offsetParent !== null) {{
                        console.log('å°è¯•å…¶ä»–è¾“å…¥æ¡†:', input.className, input.placeholder);
                    }}
                }}
            }}
        }} else {{
            console.log('âŒ æœªæ‰¾åˆ°å¿«é€Ÿè·³è½¬å®¹å™¨');
            
            // ğŸ”¥ å¤‡é€‰æ–¹æ¡ˆï¼šæŸ¥æ‰¾å…¶ä»–å¯èƒ½çš„åˆ†é¡µå…ƒç´  ğŸ”¥
            const paginationContainers = document.querySelectorAll(
                '.ant-pagination, .pagination, [class*="pagination"], [class*="pager"]'
            );
            console.log(`æ‰¾åˆ° ${{paginationContainers.length}} ä¸ªåˆ†é¡µå®¹å™¨`);
            
            for(let container of paginationContainers) {{
                console.log('åˆ†é¡µå®¹å™¨:', container.className);
                
                const inputs = container.querySelectorAll('input');
                console.log(`è¯¥å®¹å™¨ä¸­æœ‰ ${{inputs.length}} ä¸ªè¾“å…¥æ¡†`);
            }}
        }}
        """

    # Check if "No Results Found" message is present
    no_results = await check_no_results(crawler, url, session_id)
    if no_results:
        print(f" {subject_name} ç¬¬ {page_number} é¡µè·å–å¤±è´¥: {result.error_message}")
        return [], True  # No more results, signal to stop crawling

    # Fetch page content with the extraction strategy
    result = await crawler.arun(
        url=url,
        config=CrawlerRunConfig(
            cache_mode=CacheMode.BYPASS,  # Do not use cached data
            extraction_strategy=llm_strategy,  # Strategy for data extraction
            css_selector=css_selector,  # Target specific content on the page
            session_id=session_id,  # Unique session ID for the crawl
            js_code=page_navigation_js,  # ğŸ”¥ æ·»åŠ è¿™è¡Œï¼šæ‰§è¡Œé¡µç è·³è½¬JavaScript ğŸ”¥
            delay_before_return_html=8.0,  # å¢åŠ ç­‰å¾…æ—¶é—´ç¡®ä¿è·³è½¬å®Œæˆ
        ),
    )

    if not (result.success and result.extracted_content):
        print(f" {subject_name} ç¬¬ {page_number} é¡µæ— æ•°æ®")
        return [], False

    # Parse extracted content
    extracted_data = json.loads(result.extracted_content)
    if not extracted_data:
        print(f"No venues found on page {page_number}.")
        return [], False

    # After parsing extracted content
    print("Extracted data:", extracted_data)

    # Process venues
    complete_venues = []
    for venue in extracted_data:
        # Debugging: Print each venue to understand its structure
        print("Processing venue:", venue)

        # Ignore the 'error' key if it's False
        if venue.get("error") is False:
            venue.pop("error", None)  # Remove the 'error' key if it's False

        #  ä¸ºæ¯æ¡æ•°æ®æ·»åŠ å­¦ç§‘ä¿¡æ¯ 
        venue["subject"] = subject_name

        if not is_complete_venue(venue, required_keys):
            continue  # Skip incomplete venues

        if is_duplicate_venue(venue["name"], seen_names):
            print(f"Duplicate venue '{venue['name']}' found. Skipping.")
            continue  # Skip duplicate venues

        # Add venue to the list
        seen_names.add(venue["name"])
        complete_venues.append(venue)

    if not complete_venues:
        print(f"No complete venues found on page {page_number}.")
        return [], False

    print(f"Extracted {len(complete_venues)} venues from page {page_number}.")
    return complete_venues, False  # Continue crawling
