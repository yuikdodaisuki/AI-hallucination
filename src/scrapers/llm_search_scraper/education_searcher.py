"""
æ•™è‚²æ•°æ®æœç´¢å™¨ - è…¾è®¯äº‘DeepSeekè”ç½‘æœç´¢ç‰ˆæœ¬
"""
import json
import os
import time
import random
import re
from datetime import datetime
from typing import Dict, Any, List, Optional, Tuple
from openai import OpenAI
from openai.types.chat.chat_completion import Choice
from education_search_configs import education_manager, EducationSearchConfig, get_university_official_website, get_university_aliases

class EducationDataSearcher:
    """æ•™è‚²æ•°æ®æœç´¢å™¨ - è…¾è®¯äº‘DeepSeekè”ç½‘æœç´¢ç‰ˆæœ¬"""
    
    def __init__(self, client: OpenAI, target_year: int = None, base_output_dir: str = None):
        self.client = client
        self.education_manager = education_manager
        self.target_year = target_year or datetime.now().year
        
        # è¾“å‡ºç›®å½•
        if base_output_dir:
            self.base_output_dir = base_output_dir
        else:
            current_dir = os.path.dirname(os.path.abspath(__file__))
            self.base_output_dir = os.path.join(current_dir, "education_search_results")
        
        # é€Ÿç‡é™åˆ¶
        self.rpm_limit = 3
        self.request_interval = 60 / self.rpm_limit + 2
        self.last_request_time = 0
        
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {self.base_output_dir}")
        print(f"ğŸ“… ç›®æ ‡å¹´ä»½: {self.target_year}")
        print(f"ğŸ” ä½¿ç”¨è…¾è®¯äº‘DeepSeekè”ç½‘æœç´¢")

    # =============================================================================
    # ğŸ”¥ æ ¸å¿ƒæœç´¢æ–¹æ³• ğŸ”¥
    # =============================================================================
    
    def search_single_university_metric(self, config_name: str, university: str) -> Dict[str, Any]:
        """ğŸ”¥ ä¿®æ”¹ï¼šæ”¯æŒå¤šæºæœç´¢çš„å•ä¸ªå¤§å­¦æŒ‡æ ‡æœç´¢ ğŸ”¥"""
        print(f"\nğŸ” å¤šæºæœç´¢ {university} - {config_name} (æˆªæ­¢{self.target_year}å¹´)")
        
        try:
            # è·å–é…ç½®å’Œå®˜ç½‘
            config = self.education_manager.get_config(config_name)
            official_website = get_university_official_website(university)
            
            # ğŸ”¥ ä½¿ç”¨å¤šæºæœç´¢æ¶ˆæ¯åˆ›å»º ğŸ”¥
            print(f"ğŸŒ å¯ç”¨å¤šæºæƒå¨æœç´¢æ¨¡å¼")
            if official_website:
                print(f"ğŸ›ï¸ å®˜ç½‘: {official_website}")
            
            messages = education_manager.create_messages_with_multi_source_search(
                config_name, university, self.target_year
            )
            
            # æ‰§è¡Œæœç´¢
            result_content, sources, iterations = self._execute_search(messages, config)
            
            if not result_content:
                return self._create_error_result(university, config_name, "å¤šæºæœç´¢æœªå®Œæˆ")
            
            print(f"ğŸ” æœç´¢å®Œæˆï¼Œå‘ç° {len(sources)} ä¸ªæ•°æ®æº")
            
            # éªŒè¯å’Œå¤„ç†ç»“æœ
            return self._process_search_result(
                result_content, university, config_name, official_website, sources, iterations
            )
            
        except Exception as e:
            print(f"  âŒ å¤šæºæœç´¢å¤±è´¥: {e}")
            return self._create_error_result(university, config_name, str(e))
    
    def _execute_search(self, messages: List[Dict], config: EducationSearchConfig) -> Tuple[Optional[str], List[str], int]:
        """ğŸ”¥ ä¿®æ”¹ï¼šä½¿ç”¨è…¾è®¯äº‘DeepSeekè”ç½‘æœç´¢ ğŸ”¥"""
        iteration = 0
        all_sources = []
        final_result_content = None
        
        try:
            iteration = 1
            print(f"  ç¬¬ {iteration} è½®æœç´¢...")
            print(f"  ğŸ” ä½¿ç”¨è…¾è®¯äº‘DeepSeekè”ç½‘æœç´¢...")
            
            # ğŸ”¥ ç›´æ¥è°ƒç”¨ï¼Œä½¿ç”¨è”ç½‘æœç´¢ ğŸ”¥
            choice = self._chat_with_retry(messages, config)
            
            # ğŸ”¥ ç›´æ¥è·å–æœç´¢ç»“æœ ğŸ”¥
            final_result_content = choice.message.content
            print(f"    âœ… è·å¾—æœç´¢ç»“æœ: {len(final_result_content)} å­—ç¬¦")
            
            # ç®€å•çš„æºæå–
            all_sources = ["è…¾è®¯äº‘DeepSeekè”ç½‘æœç´¢"]
            
            # ğŸ”¥ æ£€æŸ¥æ˜¯å¦åŒ…å«æœç´¢æ ‡è¯† ğŸ”¥
            if any(indicator in final_result_content for indicator in ["æœç´¢", "æŸ¥æ‰¾", "æ ¹æ®", "æ˜¾ç¤º", "æ•°æ®æ˜¾ç¤º"]):
                all_sources.append("è‡ªåŠ¨è”ç½‘æœç´¢")
            
        except Exception as e:
            print(f"    âŒ æœç´¢å¤±è´¥: {e}")
        
        return final_result_content, all_sources, iteration
    
    def _process_search_result(self, result_content: str, university: str, config_name: str, 
                              official_website: str, sources: List[str], iterations: int) -> Dict[str, Any]:
        """å¤„ç†æœç´¢ç»“æœ - ç®€åŒ–ç‰ˆï¼Œç§»é™¤LLMéªŒè¯"""
        print(f"  âœ… æœç´¢å®Œæˆï¼Œå¼€å§‹éªŒè¯...")
        
        # åŸºç¡€éªŒè¯
        name_verified, name_msg = self._verify_university_name(result_content, university)
        source_verified = self._verify_official_source(result_content, official_website) if official_website else True
        data_value = self._extract_data_value(result_content, university, config_name)
        
        print(f"  ğŸ“ å­¦æ ¡éªŒè¯: {'âœ…' if name_verified else 'âŒ'} - {name_msg}")
        print(f"  ğŸ›ï¸ å®˜ç½‘éªŒè¯: {'âœ…' if source_verified else 'âŒ'}")
        print(f"  ğŸ”¢ æ•°æ®å€¼: {data_value}")
        print(f"  ğŸ“„ åŸå§‹å›ç­”: {len(result_content)} å­—ç¬¦")
        
        # ğŸ”¥ ç®€åŒ–è´¨é‡åˆ¤æ–­ ğŸ”¥
        quality_score = 0
        if name_verified: quality_score += 35
        if source_verified: quality_score += 35
        if data_value and "éœ€è¦äººå·¥æ ¸æŸ¥" not in data_value: quality_score += 30
        
        # éœ€è¦äººå·¥æ ¸æŸ¥çš„æ¡ä»¶
        needs_review = (
            not name_verified or 
            (official_website and not source_verified) or 
            "éœ€è¦äººå·¥æ ¸æŸ¥" in data_value
        )
        
        return {
            # ğŸ”¥ åŸºç¡€ä¿¡æ¯ ğŸ”¥
            "university": university,
            "metric": config_name,
            "target_year": self.target_year,
            "data_value": data_value,
            "official_website": official_website,
            
            # ğŸ”¥ éªŒè¯ä¿¡æ¯ ğŸ”¥
            "name_verification": name_verified,
            "name_verification_details": name_msg,
            "official_source_verified": source_verified,
            "data_sources": sources,
            
            # ğŸ”¥ æ ¸å¿ƒï¼šå®Œæ•´çš„åŸå§‹LLMå›ç­” ğŸ”¥
            "llm_raw_response": result_content,  # å®Œæ•´ä¿å­˜LLMåŸå§‹å›ç­”
            "response_length": len(result_content),  # å›ç­”é•¿åº¦
            "is_response_complete": not result_content.endswith("..."),  # æ£€æŸ¥æ˜¯å¦è¢«æˆªæ–­
            
            # ğŸ”¥ åŸå§‹æ•°æ® ğŸ”¥
            "search_result": result_content,  # ä¿æŒå‘åå…¼å®¹
            "search_iterations": iterations,
            "data_quality": f"è´¨é‡å¾—åˆ†:{quality_score}/100",
            "requires_manual_review": needs_review,
            "search_timestamp": datetime.now().isoformat()
        }

    # =============================================================================
    # ğŸ”¥ éªŒè¯æ–¹æ³• - åŸºç¡€éªŒè¯ ğŸ”¥
    # =============================================================================
    
    def _verify_university_name(self, result_content: str, target_university: str) -> Tuple[bool, str]:
        """ç®€åŒ–çš„å­¦æ ¡åç§°éªŒè¯"""
        # è·å–æœ‰æ•ˆåç§°
        alias_info = get_university_aliases(target_university)
        valid_names = alias_info.get("search_names", [target_university])
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æœ‰æ•ˆåç§°
        for valid_name in valid_names:
            if valid_name in result_content:
                if valid_name != target_university:
                    return True, f"éªŒè¯é€šè¿‡ï¼ˆåŒ¹é…å†å²åç§°: {valid_name}ï¼‰"
                else:
                    return True, "éªŒè¯é€šè¿‡"
        
        return False, f"æœªæ˜ç¡®æåˆ°'{target_university}'"
    
    def _verify_official_source(self, result_content: str, official_website: str) -> bool:
        """ğŸ”¥ ä¿®æ”¹ï¼šæ›´åŠ çµæ´»çš„æ•°æ®æºéªŒè¯ ğŸ”¥"""
        if not result_content:
            return False
        
        # ğŸ”¥ ç¬¬ä¸€å±‚ï¼šæ£€æŸ¥å®˜ç½‘åŸŸå ğŸ”¥
        if official_website and official_website in result_content:
            return True
        
        # ğŸ”¥ ç¬¬äºŒå±‚ï¼šæ£€æŸ¥æ”¿åºœæƒå¨ç½‘ç«™ ğŸ”¥
        government_sources = [
            'moe.gov.cn',      # æ•™è‚²éƒ¨
            'gdedu.gov.cn',    # å¹¿ä¸œçœæ•™è‚²å…
            'gov.cn',          # æ”¿åºœç½‘ç«™é€šç”¨åŸŸå
        ]
        
        for source in government_sources:
            if source in result_content:
                print(f"    ğŸ›ï¸ æ£€æµ‹åˆ°æ”¿åºœæƒå¨æº: {source}")
                return True
        
        # ğŸ”¥ ç¬¬ä¸‰å±‚ï¼šæ£€æŸ¥æƒå¨æ•™è‚²æœºæ„ ğŸ”¥
        authoritative_education = [
            'heec.edu.cn',     # é«˜ç­‰æ•™è‚²è¯„ä¼°ä¸­å¿ƒ
            'ceeaa.org.cn',    # å·¥ç¨‹æ•™è‚²è®¤è¯
            'camea.org.cn',    # åŒ»å­¦æ•™è‚²è®¤è¯
            'clarivate.com',   # ç§‘ç¿å”¯å®‰
            'webofscience.com' # Web of Science
        ]
        
        for source in authoritative_education:
            if source in result_content:
                print(f"    ğŸ“ æ£€æµ‹åˆ°æƒå¨æ•™è‚²æœºæ„: {source}")
                return True
        
        # ğŸ”¥ ç¬¬å››å±‚ï¼šæ£€æŸ¥æƒå¨åª’ä½“ï¼ˆæ¡ä»¶æ€§è®¤å¯ï¼‰ğŸ”¥
        authoritative_media = [
            'eol.cn',          # ä¸­å›½æ•™è‚²åœ¨çº¿
            'chinaedu.edu.cn', # ä¸­å›½æ•™è‚²
            'people.com.cn',   # äººæ°‘ç½‘
            'xinhuanet.com',   # æ–°åç½‘
            'china.com.cn'     # ä¸­å›½ç½‘
        ]
        
        for source in authoritative_media:
            if source in result_content:
                # åª’ä½“æºéœ€è¦é¢å¤–æ£€æŸ¥æ˜¯å¦åŒ…å«å…·ä½“æ•°æ®
                if any(indicator in result_content for indicator in ['è·å¥–', 'å¥–é¡¹', 'æˆæœ', 'åå•', 'å…¬å¸ƒ']):
                    print(f"    ğŸ“° æ£€æµ‹åˆ°æƒå¨åª’ä½“æŠ¥é“: {source}")
                    return True
        
        # ğŸ”¥ ç¬¬äº”å±‚ï¼šæ£€æŸ¥å­¦æ ¡åŸŸåç‰¹å¾ ğŸ”¥
        edu_domains = re.findall(r'[a-zA-Z0-9.-]+\.edu\.cn', result_content)
        if edu_domains:
            print(f"    ğŸ« æ£€æµ‹åˆ°æ•™è‚²æœºæ„ç½‘ç«™: {edu_domains}")
            return True
        
        print(f"    âš ï¸ æœªæ‰¾åˆ°æ˜ç¡®çš„æƒå¨æ•°æ®æº")
        return False

    def _extract_data_value(self, result_content: str, university: str, config_name: str) -> str:
        """ğŸ”¥ æ”¹è¿›æ•°æ®æå– - æ”¯æŒå¤šç§è¡¨è¾¾æ–¹å¼ ğŸ”¥"""
        
        # è·å–å†å²åç§°ç”¨äºåŒ¹é…
        alias_info = get_university_aliases(university)
        all_names = [university] + alias_info.get("historical_names", [])
        
        # ğŸ”¥ æ›´å…¨é¢çš„æ•°å­—æå–æ¨¡å¼ ğŸ”¥
        patterns = []
        
        # é’ˆå¯¹æ¯ä¸ªå¯èƒ½çš„å­¦æ ¡åç§°æ„å»ºæ¨¡å¼
        for name in all_names:
            patterns.extend([
                rf'{re.escape(name)}.*?è·å¾—.*?(\d+).*?é¡¹',
                rf'{re.escape(name)}.*?å…±.*?(\d+).*?é¡¹',
                rf'{re.escape(name)}.*?(\d+).*?ä¸ª.*?å¥–',
                rf'{re.escape(name)}.*?(\d+).*?é¡¹.*?å¥–',
                rf'{re.escape(name)}.*?è£è·.*?(\d+)',
            ])
        
        # é€šç”¨æ¨¡å¼
        patterns.extend([
            r'è·å¾—.*?(\d+).*?é¡¹',
            r'å…±.*?(\d+).*?é¡¹.*?(æ•™å­¦æˆæœå¥–|å¥–é¡¹)',
            r'(\d+).*?é¡¹.*?(çœçº§|æ•™å­¦æˆæœå¥–)',
            r'(ç‰¹ç­‰å¥–|ä¸€ç­‰å¥–|äºŒç­‰å¥–).*?(\d+).*?é¡¹',
            r'æ€»è®¡.*?(\d+).*?é¡¹',
            r'ç´¯è®¡.*?(\d+).*?é¡¹',
            r'(\d+).*?ä¸ª.*?å¥–é¡¹'
        ])
        
        # æ£€æŸ¥æ˜ç¡®çš„"æ— è·å¥–"è¡¨è¿°
        no_award_patterns = [
            r'æ²¡æœ‰.*?(è·å¾—|è·å¥–)',
            r'æœª.*?(è·å¾—|è·å¥–)',
            r'æ— .*?(è·å¥–|å¥–é¡¹)',
            r'0.*?é¡¹',
            r'æš‚æ— .*?(è·å¥–|å¥–é¡¹)'
        ]
        
        for pattern in no_award_patterns:
            if re.search(pattern, result_content, re.IGNORECASE):
                return "0"
        
        # æå–æ•°å­—
        extracted_numbers = []
        for pattern in patterns:
            matches = re.findall(pattern, result_content, re.IGNORECASE)
            if matches:
                for match in matches:
                    if isinstance(match, tuple):
                        # å¤„ç†å¤šä¸ªæ•è·ç»„çš„æƒ…å†µ
                        for item in match:
                            if item.isdigit():
                                extracted_numbers.append(int(item))
                    else:
                        if match.isdigit():
                            extracted_numbers.append(int(match))
        
        # åˆç†æ€§æ£€æŸ¥
        reasonable_range = {
            'national_teaching_awards': (0, 10),
            'provincial_teaching_awards': (0, 50),
            'youth_teacher_competition': (0, 20),
            'esi_1_percent': (0, 30),
            'national_first_class_majors': (0, 50),
            'provincial_first_class_majors': (0, 100)
        }
        
        min_val, max_val = reasonable_range.get(config_name, (0, 200))
        valid_numbers = [n for n in extracted_numbers if min_val <= n <= max_val]
        
        if valid_numbers:
            # å¦‚æœæœ‰å¤šä¸ªåˆç†æ•°å­—ï¼Œé€‰æ‹©æœ€å¤§çš„ï¼ˆé€šå¸¸æ˜¯ç´¯è®¡æ€»æ•°ï¼‰
            return str(max(valid_numbers))
        elif extracted_numbers:
            # å¦‚æœæœ‰æ•°å­—ä½†è¶…å‡ºåˆç†èŒƒå›´ï¼Œé€‰æ‹©æœ€å°çš„å¹¶æ ‡æ³¨éœ€è¦æ ¸æŸ¥
            min_number = min(extracted_numbers)
            return f"{min_number}ï¼ˆéœ€è¦äººå·¥æ ¸æŸ¥-æ•°å€¼å¯èƒ½åå¤§ï¼‰"
        
        return "éœ€è¦äººå·¥æ ¸æŸ¥-æœªæ‰¾åˆ°æ˜ç¡®æ•°å€¼"
    
    def _extract_sources_from_query(self, query: str) -> List[str]:
        """æå–æ•°æ®æº"""
        sources = []
        if "site:" in query:
            sources.append("å®˜ç½‘æœç´¢")
        if "ESI" in query:
            sources.append("ESIæ•°æ®åº“")
        if "æ•™è‚²éƒ¨" in query:
            sources.append("æ•™è‚²éƒ¨")
        return sources

    # =============================================================================
    # ğŸ”¥ å·¥å…·æ–¹æ³• ğŸ”¥
    # =============================================================================
    
    def _create_error_result(self, university: str, config_name: str, error_msg: str) -> Dict[str, Any]:
        """åˆ›å»ºé”™è¯¯ç»“æœ"""
        return {
            "university": university,
            "metric": config_name,
            "target_year": self.target_year,
            "data_value": None,
            "error": error_msg,
            "requires_manual_review": True,
            "data_quality": "è´¨é‡å¾—åˆ†:0/100",
            "search_timestamp": datetime.now().isoformat()
        }
    
    def _chat_with_retry(self, messages: List[Dict], config: EducationSearchConfig, max_attempts: int = 3) -> Choice:
        """ğŸ”¥ ä¿®æ”¹ï¼šä½¿ç”¨è…¾è®¯äº‘DeepSeek APIçš„è”ç½‘æœç´¢ ğŸ”¥"""
        for attempt in range(max_attempts):
            try:
                # é€Ÿç‡é™åˆ¶
                current_time = time.time()
                if current_time - self.last_request_time < self.request_interval:
                    time.sleep(self.request_interval)
                self.last_request_time = time.time()
                
                # ğŸ”¥ ä½¿ç”¨è…¾è®¯äº‘DeepSeekçš„è”ç½‘æœç´¢å‚æ•° ğŸ”¥
                completion = self.client.chat.completions.create(
                    model=config.model,
                    messages=messages,
                    temperature=config.temperature,
                    max_tokens=800,  # é€‚å½“é™åˆ¶tokenæ•°é‡
                    extra_body={
                        "enable_search": True  # ğŸ”¥ å¯ç”¨è…¾è®¯äº‘DeepSeekè”ç½‘æœç´¢ ğŸ”¥
                    }
                )
                return completion.choices[0]
                
            except Exception as e:
                print(f"    âŒ APIè°ƒç”¨å¤±è´¥: {e}")
                if attempt < max_attempts - 1:
                    wait_time = 2 ** attempt + random.uniform(1, 3)
                    print(f"    â° {wait_time:.1f}ç§’åé‡è¯•")
                    time.sleep(wait_time)
                else:
                    raise e
        
        raise Exception(f"APIè¯·æ±‚å¤±è´¥ï¼Œå·²å°è¯• {max_attempts} æ¬¡")

    def test_online_search_capability(self, university: str = "å¹¿å·æ–°åå­¦é™¢") -> bool:
        """ğŸ”¥ æ–°å¢ï¼šæµ‹è¯•è”ç½‘æœç´¢èƒ½åŠ› ğŸ”¥"""
        print(f"ğŸ§ª æµ‹è¯•è…¾è®¯äº‘DeepSeekè”ç½‘æœç´¢èƒ½åŠ›...")
        
        try:
            test_messages = [
                {
                    "role": "user", 
                    "content": f"è¯·æœç´¢{university}çš„ESIå‰1%å­¦ç§‘æ•°é‡ï¼Œè¦æ±‚ä½¿ç”¨æœ€æ–°æ•°æ®"
                }
            ]
            
            completion = self.client.chat.completions.create(
                model="deepseek-v3",
                messages=test_messages,
                temperature=0.1,
                max_tokens=400,
                extra_body={
                    "enable_search": True
                }
            )
            
            response = completion.choices[0].message.content
            print(f"âœ… è”ç½‘æœç´¢æµ‹è¯•æˆåŠŸ!")
            print(f"ğŸ“„ å“åº”é•¿åº¦: {len(response)} å­—ç¬¦")
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«æœç´¢ç‰¹å¾
            search_indicators = ["æœç´¢", "æŸ¥æ‰¾", "æ ¹æ®", "æ˜¾ç¤º", "æ•°æ®æ˜¾ç¤º"]
            has_search = any(indicator in response for indicator in search_indicators)
            
            print(f"ğŸ” åŒ…å«æœç´¢ç‰¹å¾: {'âœ…' if has_search else 'âŒ'}")
            
            if has_search:
                print(f"ğŸ¤– æµ‹è¯•å›ç­”æ‘˜è¦: {response[:200]}...")
            
            return True
            
        except Exception as e:
            print(f"âŒ è”ç½‘æœç´¢æµ‹è¯•å¤±è´¥: {e}")
            return False

    # =============================================================================
    # ğŸ”¥ æ‰¹é‡æœç´¢æ–¹æ³• ğŸ”¥
    # =============================================================================
    
    def search_all_universities_single_metric(self, config_name: str, universities: List[str] = None) -> Dict[str, Any]:
        """æœç´¢æ‰€æœ‰å¤§å­¦çš„å•ä¸ªæŒ‡æ ‡"""
        if universities is None:
            universities = self.education_manager.universities
        
        print(f"\nğŸš€ å¼€å§‹æœç´¢æ‰€æœ‰å¤§å­¦çš„ {config_name} æŒ‡æ ‡")
        print(f"ğŸ“Š å…±éœ€æœç´¢ {len(universities)} æ‰€å¤§å­¦")
        
        all_results = []
        start_time = time.time()
        
        for i, university in enumerate(universities, 1):
            print(f"\n[{i}/{len(universities)}] ğŸ” æœç´¢ {university}")
            
            result = self.search_single_university_metric(config_name, university)
            all_results.append(result)
            
            # ç®€å•ä¼‘æ¯
            if i < len(universities):
                time.sleep(random.uniform(2, 5))
        
        # ç”Ÿæˆæ±‡æ€»
        summary = self._create_summary(config_name, all_results)
        self._save_results(config_name, summary)
        
        total_time = time.time() - start_time
        print(f"\nğŸ‰ æœç´¢å®Œæˆ! æ€»è€—æ—¶: {total_time/60:.1f} åˆ†é’Ÿ")
        self._print_summary(summary)
        
        return summary
    
    def _create_summary(self, config_name: str, all_results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åˆ›å»ºç»“æœæ±‡æ€» - ç®€åŒ–ç‰ˆ"""
        successful_results = [r for r in all_results if "error" not in r]
        failed_results = [r for r in all_results if "error" in r]
        manual_review_needed = [r for r in successful_results if r.get("requires_manual_review", False)]
        
        # ç»Ÿè®¡åŸå§‹å›ç­”ä¿¡æ¯
        total_response_length = sum(r.get("response_length", 0) for r in successful_results)
        complete_responses = len([r for r in successful_results if r.get("is_response_complete", True)])
        
        return {
            "metric": config_name,
            "target_year": self.target_year,
            "search_completed_at": datetime.now().isoformat(),
            "total_universities": len(all_results),
            "successful_searches": len(successful_results),
            "failed_searches": len(failed_results),
            "manual_review_required": len(manual_review_needed),
            "success_rate": f"{(len(successful_results)/len(all_results)*100):.1f}%" if all_results else "0%",
            
            # åŸå§‹å›ç­”ç»Ÿè®¡
            "response_statistics": {
                "total_response_length": total_response_length,
                "average_response_length": total_response_length // len(successful_results) if successful_results else 0,
                "complete_responses": complete_responses,
                "truncated_responses": len(successful_results) - complete_responses
            },
            
            # ğŸ”¥ å¤§å­¦æ•°æ® ğŸ”¥
            "university_data": {
                result["university"]: {
                    "data_value": result.get("data_value", "æ— æ•°æ®"),
                    "name_verification": result.get("name_verification", False),
                    "official_source_verified": result.get("official_source_verified", False),
                    "data_quality": result.get("data_quality", "æœªçŸ¥"),
                    "requires_manual_review": result.get("requires_manual_review", False),
                    "llm_raw_response": result.get("llm_raw_response", ""),
                    "response_length": result.get("response_length", 0),
                    "is_response_complete": result.get("is_response_complete", True),
                    "data_sources": result.get("data_sources", [])
                }
                for result in successful_results
            },
            
            "failed_universities": [
                {"university": r["university"], "error": r.get("error", "æœªçŸ¥é”™è¯¯")}
                for r in failed_results
            ]
        }
    
    def _print_summary(self, summary: Dict[str, Any]):
        """æ‰“å°æ‘˜è¦ - ç®€åŒ–ç‰ˆ"""
        response_stats = summary.get("response_statistics", {})
        
        print(f"\nğŸ“ˆ æœç´¢æ‘˜è¦:")
        print(f"   ğŸ“Š æ€»æœç´¢: {summary['total_universities']} æ‰€å¤§å­¦")
        print(f"   âœ… æˆåŠŸ: {summary['successful_searches']} æ‰€ ({summary['success_rate']})")
        print(f"   âŒ å¤±è´¥: {summary['failed_searches']} æ‰€")
        print(f"   âš ï¸  éœ€äººå·¥æ ¸æŸ¥: {summary['manual_review_required']} æ‰€")
        
        # æ˜¾ç¤ºå›ç­”ç»Ÿè®¡
        print(f"   ğŸ“„ æ€»å›ç­”é•¿åº¦: {response_stats.get('total_response_length', 0):,} å­—ç¬¦")
        print(f"   ğŸ“Š å¹³å‡å›ç­”é•¿åº¦: {response_stats.get('average_response_length', 0):,} å­—ç¬¦")
        print(f"   âœ… å®Œæ•´å›ç­”: {response_stats.get('complete_responses', 0)} ä¸ª")
        
        truncated = response_stats.get('truncated_responses', 0)
        if truncated > 0:
            print(f"   âš ï¸  å¯èƒ½æˆªæ–­: {truncated} ä¸ª")
    
    def _save_results(self, config_name: str, summary: Dict[str, Any]):
        """ä¿å­˜ç»“æœ"""
        os.makedirs(self.base_output_dir, exist_ok=True)
        
        filename = f"{config_name}_{self.target_year}_deepseek.json"
        filepath = os.path.join(self.base_output_dir, filename)
        
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(summary, f, ensure_ascii=False, indent=2)
            print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜: {filepath}")
        except Exception as e:
            print(f"âŒ ä¿å­˜å¤±è´¥: {e}")

    # =============================================================================
    # ğŸ”¥ ä¾¿æ·æ–¹æ³• ğŸ”¥
    # =============================================================================
    
    def list_available_configs(self) -> List[str]:
        """åˆ—å‡ºå¯ç”¨é…ç½®"""
        return list(self.education_manager.list_configs().keys())
    
    def list_available_universities(self) -> List[str]:
        """åˆ—å‡ºå¯ç”¨å¤§å­¦"""
        return self.education_manager.universities
    
    def search_single_university_all_metrics(self, university: str) -> Dict[str, Any]:
        """æœç´¢å•ä¸ªå¤§å­¦çš„æ‰€æœ‰æŒ‡æ ‡"""
        configs = self.list_available_configs()
        results = {}
        
        for config_name in configs:
            print(f"\nğŸ“‹ æœç´¢ {university} - {config_name}")
            result = self.search_single_university_metric(config_name, university)
            results[config_name] = result
            time.sleep(random.uniform(3, 6))
        
        return {
            "university": university,
            "target_year": self.target_year,
            "metrics": results,
            "search_completed_at": datetime.now().isoformat()
        }

    # =============================================================================
    # ğŸ”¥ åŸå§‹å›ç­”å¯¼å‡ºå’ŒæŸ¥çœ‹æ–¹æ³• ğŸ”¥
    # =============================================================================
    
    def export_raw_responses_to_txt(self, result_file_path: str, output_txt_path: str = None) -> str:
        """ğŸ”¥ å¯¼å‡ºåŸå§‹LLMå›ç­”åˆ°æ–‡æœ¬æ–‡ä»¶ ğŸ”¥"""
        if output_txt_path is None:
            base_name = os.path.splitext(os.path.basename(result_file_path))[0]
            output_txt_path = os.path.join(
                os.path.dirname(result_file_path), 
                f"{base_name}_raw_responses.txt"
            )
        
        try:
            # è¯»å–JSONç»“æœ
            with open(result_file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # æå–å¤§å­¦æ•°æ®
            university_data = data.get("university_data", {})
            metric = data.get("metric", "unknown_metric")
            target_year = data.get("target_year", "unknown_year")
            
            # å†™å…¥æ–‡æœ¬æ–‡ä»¶
            with open(output_txt_path, 'w', encoding='utf-8') as f:
                f.write(f"=" * 80 + "\n")
                f.write(f"LLMåŸå§‹å›ç­”å¯¼å‡º - {metric} ({target_year}å¹´)\n")
                f.write(f"å¯¼å‡ºæ—¶é—´: {datetime.now().isoformat()}\n")
                f.write(f"æ€»è®¡: {len(university_data)} æ‰€å¤§å­¦\n")
                f.write(f"æœç´¢å¼•æ“: è…¾è®¯äº‘DeepSeekè”ç½‘æœç´¢\n")
                f.write(f"=" * 80 + "\n\n")
                
                for i, (university, info) in enumerate(university_data.items(), 1):
                    f.write(f"[{i:02d}] {university}\n")
                    f.write(f"{'=' * 50}\n")
                    f.write(f"æ•°æ®å€¼: {info.get('data_value', 'æ— æ•°æ®')}\n")
                    f.write(f"å›ç­”é•¿åº¦: {info.get('response_length', 0)} å­—ç¬¦\n")
                    f.write(f"å®Œæ•´æ€§: {'âœ… å®Œæ•´' if info.get('is_response_complete', True) else 'âš ï¸ å¯èƒ½æˆªæ–­'}\n")
                    f.write(f"æ•°æ®æº: {', '.join(info.get('data_sources', []))}\n")
                    f.write(f"-" * 50 + "\n")
                    
                    # ğŸ”¥ å®Œæ•´çš„LLMåŸå§‹å›ç­” ğŸ”¥
                    raw_response = info.get('llm_raw_response', 'æ— å›ç­”')
                    f.write(f"LLMåŸå§‹å›ç­”:\n{raw_response}\n")
                    
                    f.write(f"\n" + "=" * 80 + "\n\n")
            
            print(f"ğŸ’¾ åŸå§‹å›ç­”å·²å¯¼å‡º: {output_txt_path}")
            return output_txt_path
            
        except Exception as e:
            print(f"âŒ å¯¼å‡ºåŸå§‹å›ç­”å¤±è´¥: {e}")
            raise e

    def get_single_university_raw_response(self, result_file_path: str, university_name: str) -> str:
        """ğŸ”¥ è·å–å•ä¸ªå¤§å­¦çš„åŸå§‹å›ç­” ğŸ”¥"""
        try:
            with open(result_file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            university_data = data.get("university_data", {})
            if university_name in university_data:
                info = university_data[university_name]
                raw_response = info.get('llm_raw_response', '')
                
                print(f"ğŸ“„ {university_name} çš„åŸå§‹å›ç­” ({len(raw_response)} å­—ç¬¦):")
                print("-" * 50)
                print(raw_response)
                print("-" * 50)
                
                return raw_response
            else:
                print(f"âŒ æœªæ‰¾åˆ° {university_name} çš„æ•°æ®")
                return ""
                
        except Exception as e:
            print(f"âŒ è¯»å–å¤±è´¥: {e}")
            return ""

    def show_response_summary(self, result_file_path: str):
        """ğŸ”¥ æ˜¾ç¤ºå›ç­”æ¦‚è¦ç»Ÿè®¡ ğŸ”¥"""
        try:
            with open(result_file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            university_data = data.get("university_data", {})
            response_stats = data.get("response_statistics", {})
            
            print(f"\nğŸ“Š å›ç­”ç»Ÿè®¡æ‘˜è¦:")
            print(f"   ğŸ“„ æ€»å›ç­”é•¿åº¦: {response_stats.get('total_response_length', 0):,} å­—ç¬¦")
            print(f"   ğŸ“Š å¹³å‡å›ç­”é•¿åº¦: {response_stats.get('average_response_length', 0):,} å­—ç¬¦")
            print(f"   âœ… å®Œæ•´å›ç­”: {response_stats.get('complete_responses', 0)} ä¸ª")
            print(f"   âš ï¸  å¯èƒ½æˆªæ–­: {response_stats.get('truncated_responses', 0)} ä¸ª")
            
            print(f"\nğŸ“‹ å¤§å­¦å›ç­”é•¿åº¦æ’è¡Œ:")
            # æŒ‰å›ç­”é•¿åº¦æ’åº
            universities_by_length = sorted(
                university_data.items(), 
                key=lambda x: x[1].get('response_length', 0), 
                reverse=True
            )
            
            for i, (university, info) in enumerate(universities_by_length[:10], 1):
                length = info.get('response_length', 0)
                complete = 'âœ…' if info.get('is_response_complete', True) else 'âš ï¸'
                print(f"   {i:2d}. {university}: {length:,} å­—ç¬¦ {complete}")
                
        except Exception as e:
            print(f"âŒ æ˜¾ç¤ºç»Ÿè®¡å¤±è´¥: {e}")